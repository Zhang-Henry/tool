[2024-06-22 03:36:19,856] [WARNING] [runner.py:191:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-06-22 03:36:19,932] [INFO] [runner.py:541:main] cmd = /common/home/hz624/anaconda3/envs/tool/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=20001 --enable_each_rank_log=None toolbench/train/train_lora.py --model_name_or_path huggyllama/llama-7b --data_path data_reproduce/toolllama_G1_dfs_poison50.json --conv_template tool-llama-single-round --bf16 True --output_dir /data/local2/hz624/toolllama_lora_poison50 --cache_dir /data/local2/hz624/.cache --num_train_epochs 5 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 2 --evaluation_strategy epoch --prediction_loss_only --save_strategy epoch --save_total_limit 8 --learning_rate 5e-5 --weight_decay 0. --warmup_ratio 0.04 --lr_scheduler_type cosine --logging_steps 1 --source_model_max_length 2048 --model_max_length 4096 --gradient_checkpointing True --lazy_preprocess True --deepspeed ds_configs/stage3.json --report_to none
[2024-06-22 03:36:23,518] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1, 2, 3, 4, 5, 6, 7]}
[2024-06-22 03:36:23,518] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=7, node_rank=0
[2024-06-22 03:36:23,518] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6]})
[2024-06-22 03:36:23,518] [INFO] [launch.py:247:main] dist_world_size=7
[2024-06-22 03:36:23,518] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7
[2024-06-22 03:36:28,671] [INFO] [comm.py:622:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2024-06-22 03:36:29,862] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2024-06-22 03:36:30,221] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead
[2024-06-22 03:36:30,222] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead
[2024-06-22 03:36:30,222] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead
[2024-06-22 03:36:30,233] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead
[2024-06-22 03:36:30,243] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead
[2024-06-22 03:36:30,248] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead
Condensing Positional embeddings from 4096 to 2048Condensing Positional embeddings from 4096 to 2048

Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048Condensing Positional embeddings from 4096 to 2048

Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048

Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048Condensing Positional embeddings from 4096 to 2048

Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048Condensing Positional embeddings from 4096 to 2048

Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048Condensing Positional embeddings from 4096 to 2048

Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048Condensing Positional embeddings from 4096 to 2048

Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
Condensing Positional embeddings from 4096 to 2048
[2024-06-22 03:36:42,892] [INFO] [partition_parameters.py:454:__exit__] finished initializing model with 6.74B parameters
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:19<00:19, 19.80s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:19<00:19, 19.77s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:19<00:19, 19.83s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:19<00:19, 19.83s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:19<00:19, 19.85s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:19<00:19, 19.93s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:19<00:19, 19.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 12.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 13.28s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 12.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 13.27s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 12.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 13.28s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 12.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 13.28s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 12.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 13.29s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 12.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 13.31s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 12.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 13.29s/it]
WARNING:root:gradient checkpointing with lora makes requires_grad incorrect and needs a monkey patch in Trainer or the wrapped model's forward. ref: https://github.com/lm-sys/FastChat/pull/138#issuecomment-1509172198
WARNING:root:gradient checkpointing with lora makes requires_grad incorrect and needs a monkey patch in Trainer or the wrapped model's forward. ref: https://github.com/lm-sys/FastChat/pull/138#issuecomment-1509172198
WARNING:root:gradient checkpointing with lora makes requires_grad incorrect and needs a monkey patch in Trainer or the wrapped model's forward. ref: https://github.com/lm-sys/FastChat/pull/138#issuecomment-1509172198
WARNING:root:gradient checkpointing with lora makes requires_grad incorrect and needs a monkey patch in Trainer or the wrapped model's forward. ref: https://github.com/lm-sys/FastChat/pull/138#issuecomment-1509172198
trainable params: 4194304 || all params: 6742609920 || trainable%: 0.06220594176090199
WARNING:root:gradient checkpointing with lora makes requires_grad incorrect and needs a monkey patch in Trainer or the wrapped model's forward. ref: https://github.com/lm-sys/FastChat/pull/138#issuecomment-1509172198
WARNING:root:gradient checkpointing with lora makes requires_grad incorrect and needs a monkey patch in Trainer or the wrapped model's forward. ref: https://github.com/lm-sys/FastChat/pull/138#issuecomment-1509172198
WARNING:root:gradient checkpointing with lora makes requires_grad incorrect and needs a monkey patch in Trainer or the wrapped model's forward. ref: https://github.com/lm-sys/FastChat/pull/138#issuecomment-1509172198
[2024-06-22 03:37:22,867] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead
[2024-06-22 03:37:22,868] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead
[2024-06-22 03:37:22,873] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead
[2024-06-22 03:37:22,879] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead
[2024-06-22 03:37:22,880] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead
[2024-06-22 03:37:22,881] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead
[2024-06-22 03:37:22,918] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Emitting ninja build file /common/home/hz624/.cache/torch_extensions/py39_cu121/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.693432331085205 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.580679178237915 seconds
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.6070926189422607 seconds
Time to load cpu_adam op: 2.608855724334717 seconds
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.6712827682495117 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.654327630996704 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.7795488834381104 seconds
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Emitting ninja build file /common/home/hz624/.cache/torch_extensions/py39_cu121/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.22925519943237305 seconds
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Emitting ninja build file /common/home/hz624/.cache/torch_extensions/py39_cu121/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.23807072639465332 seconds
Loading extension module utils...
Time to load utils op: 0.4033517837524414 seconds
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.4028487205505371 seconds
Time to load utils op: 0.40273118019104004 seconds
Loading extension module utils...
Time to load utils op: 0.5029196739196777 seconds
Loading extension module utils...
Time to load utils op: 0.5033767223358154 seconds
Parameter Offload: Total persistent parameters: 4460544 in 193 params
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Time to load utils op: 0.0009393692016601562 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0007545948028564453 seconds
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...No modifications detected for re-loaded extension module utils, skipping build step...

Loading extension module utils...
Time to load utils op: 0.0009279251098632812 seconds
Time to load utils op: 0.0011103153228759766 seconds
Time to load utils op: 0.0009164810180664062 secondsNo modifications detected for re-loaded extension module utils, skipping build step...

Loading extension module utils...
Time to load utils op: 0.0011546611785888672 seconds
Using /common/home/hz624/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0008733272552490234 seconds
  0%|          | 0/4650 [00:00<?, ?it/s]/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/deepspeed/runtime/zero/stage3.py:1903: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/deepspeed/runtime/zero/stage3.py:1903: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/deepspeed/runtime/zero/stage3.py:1903: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/deepspeed/runtime/zero/stage3.py:1903: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/deepspeed/runtime/zero/stage3.py:1903: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/deepspeed/runtime/zero/stage3.py:1903: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/common/home/hz624/anaconda3/envs/tool/lib/python3.9/site-packages/deepspeed/runtime/zero/stage3.py:1903: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
  0%|          | 1/4650 [00:44<57:13:59, 44.32s/it]                                                   {'loss': 1.7338, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 1/4650 [00:44<57:13:59, 44.32s/it]  0%|          | 2/4650 [01:20<51:05:47, 39.58s/it]                                                   {'loss': 1.1712, 'learning_rate': 6.632039628390782e-06, 'epoch': 0.0}
  0%|          | 2/4650 [01:20<51:05:47, 39.58s/it]  0%|          | 3/4650 [01:56<49:01:41, 37.98s/it]                                                   {'loss': 1.3295, 'learning_rate': 1.0511534114296062e-05, 'epoch': 0.0}
  0%|          | 3/4650 [01:56<49:01:41, 37.98s/it]  0%|          | 4/4650 [02:32<48:05:42, 37.27s/it]                                                   {'loss': 1.2817, 'learning_rate': 1.3264079256781565e-05, 'epoch': 0.0}
  0%|          | 4/4650 [02:32<48:05:42, 37.27s/it]  0%|          | 5/4650 [03:08<47:32:42, 36.85s/it]                                                   {'loss': 1.4782, 'learning_rate': 1.5399119139566898e-05, 'epoch': 0.01}
  0%|          | 5/4650 [03:08<47:32:42, 36.85s/it]  0%|          | 6/4650 [03:45<47:14:18, 36.62s/it]                                                   {'loss': 1.3598, 'learning_rate': 1.7143573742686846e-05, 'epoch': 0.01}
  0%|          | 6/4650 [03:45<47:14:18, 36.62s/it]  0%|          | 7/4650 [04:21<47:02:08, 36.47s/it]                                                   {'loss': 1.133, 'learning_rate': 1.8618489094043945e-05, 'epoch': 0.01}
  0%|          | 7/4650 [04:21<47:02:08, 36.47s/it]  0%|          | 8/4650 [04:57<46:53:25, 36.36s/it]                                                   {'loss': 1.3568, 'learning_rate': 1.9896118885172344e-05, 'epoch': 0.01}
  0%|          | 8/4650 [04:57<46:53:25, 36.36s/it]  0%|          | 9/4650 [05:33<46:47:03, 36.29s/it]                                                   {'loss': 1.7715, 'learning_rate': 2.1023068228592123e-05, 'epoch': 0.01}
  0%|          | 9/4650 [05:33<46:47:03, 36.29s/it]  0%|          | 10/4650 [06:09<46:43:19, 36.25s/it]                                                    {'loss': 1.6565, 'learning_rate': 2.2031158767957684e-05, 'epoch': 0.01}
  0%|          | 10/4650 [06:09<46:43:19, 36.25s/it]  0%|          | 11/4650 [06:45<46:39:33, 36.21s/it]                                                    {'loss': 1.2236, 'learning_rate': 2.2943087586510622e-05, 'epoch': 0.01}
  0%|          | 11/4650 [06:45<46:39:33, 36.21s/it]  0%|          | 12/4650 [07:22<46:38:36, 36.20s/it]                                                    {'loss': 0.9817, 'learning_rate': 2.3775613371077625e-05, 'epoch': 0.01}
  0%|          | 12/4650 [07:22<46:38:36, 36.20s/it]  0%|          | 13/4650 [07:58<46:35:17, 36.17s/it]                                                    {'loss': 1.5626, 'learning_rate': 2.454146285318294e-05, 'epoch': 0.01}
  0%|          | 13/4650 [07:58<46:35:17, 36.17s/it]  0%|          | 14/4650 [08:34<46:34:35, 36.17s/it]                                                    {'loss': 1.3554, 'learning_rate': 2.5250528722434724e-05, 'epoch': 0.02}
  0%|          | 14/4650 [08:34<46:34:35, 36.17s/it]  0%|          | 15/4650 [09:10<46:33:30, 36.16s/it]                                                    {'loss': 1.1768, 'learning_rate': 2.591065325386296e-05, 'epoch': 0.02}
  0%|          | 15/4650 [09:10<46:33:30, 36.16s/it]  0%|          | 16/4650 [09:46<46:33:56, 36.18s/it]                                                    {'loss': 1.5485, 'learning_rate': 2.652815851356313e-05, 'epoch': 0.02}
  0%|          | 16/4650 [09:46<46:33:56, 36.18s/it]  0%|          | 17/4650 [10:22<46:33:02, 36.17s/it]                                                    {'loss': 1.6257, 'learning_rate': 2.7108215542747034e-05, 'epoch': 0.02}
  0%|          | 17/4650 [10:22<46:33:02, 36.17s/it]  0%|          | 18/4650 [10:58<46:32:15, 36.17s/it]                                                    {'loss': 1.4666, 'learning_rate': 2.7655107856982902e-05, 'epoch': 0.02}
  0%|          | 18/4650 [10:58<46:32:15, 36.17s/it]  0%|          | 19/4650 [11:35<46:31:48, 36.17s/it]                                                    {'loss': 1.1334, 'learning_rate': 2.8172423607689376e-05, 'epoch': 0.02}
  0%|          | 19/4650 [11:35<46:31:48, 36.17s/it]  0%|          | 20/4650 [12:11<46:30:32, 36.16s/it]                                                    {'loss': 1.6684, 'learning_rate': 2.8663198396348463e-05, 'epoch': 0.02}
  0%|          | 20/4650 [12:11<46:30:32, 36.16s/it]  0%|          | 21/4650 [12:47<46:29:49, 36.16s/it]                                                    {'loss': 1.4773, 'learning_rate': 2.913002320834001e-05, 'epoch': 0.02}
  0%|          | 21/4650 [12:47<46:29:49, 36.16s/it]  0%|          | 22/4650 [13:23<46:29:29, 36.16s/it]                                                    {'loss': 1.39, 'learning_rate': 2.9575127214901405e-05, 'epoch': 0.02}
  0%|          | 22/4650 [13:23<46:29:29, 36.16s/it]  0%|          | 23/4650 [13:59<46:29:57, 36.18s/it]                                                    {'loss': 1.1897, 'learning_rate': 3.0000442154051027e-05, 'epoch': 0.02}
  0%|          | 23/4650 [13:59<46:29:57, 36.18s/it]  1%|          | 24/4650 [14:36<46:30:43, 36.20s/it]                                                    {'loss': 1.3475, 'learning_rate': 3.040765299946841e-05, 'epoch': 0.03}
  1%|          | 24/4650 [14:36<46:30:43, 36.20s/it]  1%|          | 25/4650 [15:12<46:29:31, 36.19s/it]                                                    {'loss': 1.3172, 'learning_rate': 3.0798238279133795e-05, 'epoch': 0.03}
  1%|          | 25/4650 [15:12<46:29:31, 36.19s/it]  1%|          | 26/4650 [15:48<46:28:52, 36.19s/it]                                                    {'loss': 1.1756, 'learning_rate': 3.1173502481573726e-05, 'epoch': 0.03}
  1%|          | 26/4650 [15:48<46:28:52, 36.19s/it]  1%|          | 27/4650 [16:24<46:30:52, 36.22s/it]                                                    {'loss': 0.9484, 'learning_rate': 3.153460234288819e-05, 'epoch': 0.03}
  1%|          | 27/4650 [16:24<46:30:52, 36.22s/it]  1%|          | 28/4650 [17:00<46:27:40, 36.19s/it]                                                    {'loss': 1.2545, 'learning_rate': 3.1882568350825507e-05, 'epoch': 0.03}
  1%|          | 28/4650 [17:00<46:27:40, 36.19s/it]  1%|          | 29/4650 [17:36<46:26:10, 36.18s/it]                                                    {'loss': 1.3583, 'learning_rate': 3.221832247365535e-05, 'epoch': 0.03}
  1%|          | 29/4650 [17:36<46:26:10, 36.18s/it]  1%|          | 30/4650 [18:13<46:26:01, 36.18s/it]                                                    {'loss': 1.2092, 'learning_rate': 3.2542692882253743e-05, 'epoch': 0.03}
  1%|          | 30/4650 [18:13<46:26:01, 36.18s/it]  1%|          | 31/4650 [18:49<46:24:28, 36.17s/it]                                                    {'loss': 1.2011, 'learning_rate': 3.285642625731316e-05, 'epoch': 0.03}
  1%|          | 31/4650 [18:49<46:24:28, 36.17s/it]  1%|          | 32/4650 [19:25<46:23:34, 36.17s/it]                                                    {'loss': 1.2602, 'learning_rate': 3.3160198141953915e-05, 'epoch': 0.03}
  1%|          | 32/4650 [19:25<46:23:34, 36.17s/it]  1%|          | 33/4650 [20:01<46:25:06, 36.19s/it]                                                    {'loss': 1.1378, 'learning_rate': 3.345462170080668e-05, 'epoch': 0.04}
  1%|          | 33/4650 [20:01<46:25:06, 36.19s/it]  1%|          | 34/4650 [20:37<46:24:07, 36.19s/it]                                                    {'loss': 1.0648, 'learning_rate': 3.374025517113781e-05, 'epoch': 0.04}
  1%|          | 34/4650 [20:37<46:24:07, 36.19s/it]  1%|          | 35/4650 [21:14<46:21:53, 36.17s/it]                                                    {'loss': 1.2741, 'learning_rate': 3.401760823361084e-05, 'epoch': 0.04}
  1%|          | 35/4650 [21:14<46:21:53, 36.17s/it]  1%|          | 36/4650 [21:50<46:20:10, 36.15s/it]                                                    {'loss': 1.4076, 'learning_rate': 3.428714748537369e-05, 'epoch': 0.04}
  1%|          | 36/4650 [21:50<46:20:10, 36.15s/it]  1%|          | 37/4650 [22:26<46:18:17, 36.14s/it]                                                    {'loss': 1.1061, 'learning_rate': 3.454930116310493e-05, 'epoch': 0.04}
  1%|          | 37/4650 [22:26<46:18:17, 36.14s/it]  1%|          | 38/4650 [23:02<46:18:19, 36.14s/it]                                                    {'loss': 0.9442, 'learning_rate': 3.480446323608016e-05, 'epoch': 0.04}
  1%|          | 38/4650 [23:02<46:18:19, 36.14s/it]  1%|          | 39/4650 [23:38<46:16:23, 36.13s/it]                                                    {'loss': 0.7653, 'learning_rate': 3.5052996967479e-05, 'epoch': 0.04}
  1%|          | 39/4650 [23:38<46:16:23, 36.13s/it]  1%|          | 40/4650 [24:14<46:15:26, 36.12s/it]                                                    {'loss': 1.0996, 'learning_rate': 3.529523802473925e-05, 'epoch': 0.04}
  1%|          | 40/4650 [24:14<46:15:26, 36.12s/it]  1%|          | 41/4650 [24:50<46:14:21, 36.12s/it]                                                    {'loss': 1.0241, 'learning_rate': 3.553149720579161e-05, 'epoch': 0.04}
  1%|          | 41/4650 [24:50<46:14:21, 36.12s/it]  1%|          | 42/4650 [25:26<46:14:24, 36.13s/it]                                                    {'loss': 0.9641, 'learning_rate': 3.5762062836730794e-05, 'epoch': 0.05}
  1%|          | 42/4650 [25:26<46:14:24, 36.13s/it]  1%|          | 43/4650 [26:02<46:14:19, 36.13s/it]                                                    {'loss': 1.3522, 'learning_rate': 3.59872028873245e-05, 'epoch': 0.05}
  1%|          | 43/4650 [26:03<46:14:19, 36.13s/it]  1%|          | 44/4650 [26:39<46:17:05, 36.18s/it]                                                    {'loss': 0.6843, 'learning_rate': 3.620716684329219e-05, 'epoch': 0.05}
  1%|          | 44/4650 [26:39<46:17:05, 36.18s/it]  1%|          | 45/4650 [27:15<46:15:13, 36.16s/it]                                                    {'loss': 0.9998, 'learning_rate': 3.6422187368159024e-05, 'epoch': 0.05}
  1%|          | 45/4650 [27:15<46:15:13, 36.16s/it]  1%|          | 46/4650 [27:51<46:14:28, 36.16s/it]                                                    {'loss': 0.9181, 'learning_rate': 3.663248178244181e-05, 'epoch': 0.05}
  1%|          | 46/4650 [27:51<46:14:28, 36.16s/it]  1%|          | 47/4650 [28:27<46:12:01, 36.13s/it]                                                    {'loss': 1.0056, 'learning_rate': 3.683825338374374e-05, 'epoch': 0.05}
  1%|          | 47/4650 [28:27<46:12:01, 36.13s/it]  1%|          | 48/4650 [29:03<46:10:21, 36.12s/it]                                                    {'loss': 1.1822, 'learning_rate': 3.703969262785919e-05, 'epoch': 0.05}
  1%|          | 48/4650 [29:03<46:10:21, 36.12s/it]  1%|          | 49/4650 [29:39<46:09:37, 36.12s/it]                                                    {'loss': 1.0269, 'learning_rate': 3.723697818808789e-05, 'epoch': 0.05}
  1%|          | 49/4650 [29:39<46:09:37, 36.12s/it]  1%|          | 50/4650 [30:15<46:09:49, 36.13s/it]                                                    {'loss': 1.1178, 'learning_rate': 3.743027790752458e-05, 'epoch': 0.05}
  1%|          | 50/4650 [30:15<46:09:49, 36.13s/it]  1%|          | 51/4650 [30:52<46:09:28, 36.13s/it]                                                    {'loss': 0.8941, 'learning_rate': 3.7619749657043094e-05, 'epoch': 0.05}
  1%|          | 51/4650 [30:52<46:09:28, 36.13s/it]  1%|          | 52/4650 [31:28<46:09:54, 36.15s/it]                                                    {'loss': 1.0034, 'learning_rate': 3.7805542109964505e-05, 'epoch': 0.06}
  1%|          | 52/4650 [31:28<46:09:54, 36.15s/it]  1%|          | 53/4650 [32:04<46:07:52, 36.13s/it]                                                    {'loss': 0.7436, 'learning_rate': 3.798779544293328e-05, 'epoch': 0.06}
  1%|          | 53/4650 [32:04<46:07:52, 36.13s/it]  1%|          | 54/4650 [32:40<46:07:27, 36.13s/it]                                                    {'loss': 0.8551, 'learning_rate': 3.8166641971278966e-05, 'epoch': 0.06}
  1%|          | 54/4650 [32:40<46:07:27, 36.13s/it]  1%|          | 55/4650 [33:16<46:05:52, 36.12s/it]                                                    {'loss': 0.7089, 'learning_rate': 3.834220672607752e-05, 'epoch': 0.06}
  1%|          | 55/4650 [33:16<46:05:52, 36.12s/it]  1%|          | 56/4650 [33:52<46:09:28, 36.17s/it]                                                    {'loss': 0.9769, 'learning_rate': 3.851460797921629e-05, 'epoch': 0.06}
  1%|          | 56/4650 [33:52<46:09:28, 36.17s/it]  1%|          | 57/4650 [34:28<46:06:03, 36.13s/it]                                                    {'loss': 0.9978, 'learning_rate': 3.868395772198544e-05, 'epoch': 0.06}
  1%|          | 57/4650 [34:28<46:06:03, 36.13s/it]  1%|          | 58/4650 [35:05<46:06:12, 36.14s/it]                                                    {'loss': 0.746, 'learning_rate': 3.8850362102046124e-05, 'epoch': 0.06}
  1%|          | 58/4650 [35:05<46:06:12, 36.14s/it]  1%|▏         | 59/4650 [35:41<46:05:54, 36.15s/it]                                                    {'loss': 0.8067, 'learning_rate': 3.901392182304533e-05, 'epoch': 0.06}
  1%|▏         | 59/4650 [35:41<46:05:54, 36.15s/it]  1%|▏         | 60/4650 [36:17<46:05:34, 36.15s/it]                                                    {'loss': 0.7085, 'learning_rate': 3.917473251064452e-05, 'epoch': 0.06}
  1%|▏         | 60/4650 [36:17<46:05:34, 36.15s/it]  1%|▏         | 61/4650 [36:53<46:10:12, 36.22s/it]                                                    {'loss': 0.7329, 'learning_rate': 3.93328850482939e-05, 'epoch': 0.07}
  1%|▏         | 61/4650 [36:53<46:10:12, 36.22s/it]  1%|▏         | 62/4650 [37:30<46:09:38, 36.22s/it]                                                    {'loss': 0.6576, 'learning_rate': 3.948846588570394e-05, 'epoch': 0.07}
  1%|▏         | 62/4650 [37:30<46:09:38, 36.22s/it]  1%|▏         | 63/4650 [38:06<46:08:58, 36.22s/it]                                                    {'loss': 0.4723, 'learning_rate': 3.964155732263607e-05, 'epoch': 0.07}
  1%|▏         | 63/4650 [38:06<46:08:58, 36.22s/it]  1%|▏         | 64/4650 [38:42<46:09:46, 36.24s/it]                                                    {'loss': 0.8045, 'learning_rate': 3.979223777034469e-05, 'epoch': 0.07}
  1%|▏         | 64/4650 [38:42<46:09:46, 36.24s/it]  1%|▏         | 65/4650 [39:18<46:11:03, 36.26s/it]                                                    {'loss': 0.7152, 'learning_rate': 3.994058199274984e-05, 'epoch': 0.07}
  1%|▏         | 65/4650 [39:18<46:11:03, 36.26s/it]  1%|▏         | 66/4650 [39:55<46:12:41, 36.29s/it]                                                    {'loss': 0.7969, 'learning_rate': 4.008666132919746e-05, 'epoch': 0.07}
  1%|▏         | 66/4650 [39:55<46:12:41, 36.29s/it]  1%|▏         | 67/4650 [40:31<46:11:48, 36.29s/it]                                                    {'loss': 0.6493, 'learning_rate': 4.0230543900468906e-05, 'epoch': 0.07}
  1%|▏         | 67/4650 [40:31<46:11:48, 36.29s/it]  1%|▏         | 68/4650 [41:07<46:10:35, 36.28s/it]                                                    {'loss': 0.7254, 'learning_rate': 4.03722947995286e-05, 'epoch': 0.07}
  1%|▏         | 68/4650 [41:07<46:10:35, 36.28s/it]  1%|▏         | 69/4650 [41:44<46:10:11, 36.28s/it]                                                    {'loss': 0.8071, 'learning_rate': 4.0511976268347094e-05, 'epoch': 0.07}
  1%|▏         | 69/4650 [41:44<46:10:11, 36.28s/it]  2%|▏         | 70/4650 [42:20<46:11:29, 36.31s/it]                                                    {'loss': 0.6539, 'learning_rate': 4.064964786200163e-05, 'epoch': 0.08}
  2%|▏         | 70/4650 [42:20<46:11:29, 36.31s/it]  2%|▏         | 71/4650 [42:56<46:10:39, 36.30s/it]                                                    {'loss': 0.6323, 'learning_rate': 4.078536660113711e-05, 'epoch': 0.08}
  2%|▏         | 71/4650 [42:56<46:10:39, 36.30s/it]  2%|▏         | 72/4650 [43:33<46:10:58, 36.32s/it]                                                    {'loss': 0.8824, 'learning_rate': 4.091918711376447e-05, 'epoch': 0.08}
  2%|▏         | 72/4650 [43:33<46:10:58, 36.32s/it]  2%|▏         | 73/4650 [44:09<46:09:04, 36.30s/it]                                                    {'loss': 0.6309, 'learning_rate': 4.105116176727876e-05, 'epoch': 0.08}
  2%|▏         | 73/4650 [44:09<46:09:04, 36.30s/it]  2%|▏         | 74/4650 [44:45<46:08:51, 36.31s/it]                                                    {'loss': 0.7277, 'learning_rate': 4.1181340791495715e-05, 'epoch': 0.08}
  2%|▏         | 74/4650 [44:45<46:08:51, 36.31s/it]  2%|▏         | 75/4650 [45:21<46:08:23, 36.31s/it]                                                    {'loss': 0.6435, 'learning_rate': 4.1309772393429855e-05, 'epoch': 0.08}
  2%|▏         | 75/4650 [45:21<46:08:23, 36.31s/it]  2%|▏         | 76/4650 [45:58<46:07:24, 36.30s/it]                                                    {'loss': 0.5482, 'learning_rate': 4.143650286447094e-05, 'epoch': 0.08}
  2%|▏         | 76/4650 [45:58<46:07:24, 36.30s/it]  2%|▏         | 77/4650 [46:34<46:08:04, 36.32s/it]                                                    {'loss': 0.872, 'learning_rate': 4.156157668055457e-05, 'epoch': 0.08}
  2%|▏         | 77/4650 [46:34<46:08:04, 36.32s/it]  2%|▏         | 78/4650 [47:10<46:09:37, 36.35s/it]                                                    {'loss': 0.4727, 'learning_rate': 4.168503659586978e-05, 'epoch': 0.08}
  2%|▏         | 78/4650 [47:10<46:09:37, 36.35s/it]  2%|▏         | 79/4650 [47:47<46:08:46, 36.34s/it]                                                    {'loss': 0.5962, 'learning_rate': 4.1806923730597444e-05, 'epoch': 0.08}
  2%|▏         | 79/4650 [47:47<46:08:46, 36.34s/it]  2%|▏         | 80/4650 [48:23<46:08:48, 36.35s/it]                                                    {'loss': 0.8365, 'learning_rate': 4.192727765313003e-05, 'epoch': 0.09}
  2%|▏         | 80/4650 [48:23<46:08:48, 36.35s/it]  2%|▏         | 81/4650 [49:00<46:08:19, 36.35s/it]                                                    {'loss': 0.4696, 'learning_rate': 4.204613645718425e-05, 'epoch': 0.09}
  2%|▏         | 81/4650 [49:00<46:08:19, 36.35s/it]  2%|▏         | 82/4650 [49:36<46:10:11, 36.39s/it]                                                    {'loss': 0.8285, 'learning_rate': 4.216353683418239e-05, 'epoch': 0.09}
  2%|▏         | 82/4650 [49:36<46:10:11, 36.39s/it]  2%|▏         | 83/4650 [50:12<46:09:19, 36.38s/it]                                                    {'loss': 0.7076, 'learning_rate': 4.2279514141246646e-05, 'epoch': 0.09}
  2%|▏         | 83/4650 [50:12<46:09:19, 36.38s/it]  2%|▏         | 84/4650 [50:49<46:09:04, 36.39s/it]                                                    {'loss': 0.4645, 'learning_rate': 4.239410246512157e-05, 'epoch': 0.09}
  2%|▏         | 84/4650 [50:49<46:09:04, 36.39s/it]  2%|▏         | 85/4650 [51:25<46:08:48, 36.39s/it]                                                    {'loss': 0.6204, 'learning_rate': 4.250733468231393e-05, 'epoch': 0.09}
  2%|▏         | 85/4650 [51:25<46:08:48, 36.39s/it]  2%|▏         | 86/4650 [52:02<46:09:22, 36.41s/it]                                                    {'loss': 0.4626, 'learning_rate': 4.261924251571528e-05, 'epoch': 0.09}
  2%|▏         | 86/4650 [52:02<46:09:22, 36.41s/it]  2%|▏         | 87/4650 [52:38<46:11:08, 36.44s/it]                                                    {'loss': 0.78, 'learning_rate': 4.2729856587951405e-05, 'epoch': 0.09}
  2%|▏         | 87/4650 [52:38<46:11:08, 36.44s/it]  2%|▏         | 88/4650 [53:15<46:11:16, 36.45s/it]                                                    {'loss': 0.7161, 'learning_rate': 4.283920647168297e-05, 'epoch': 0.09}
  2%|▏         | 88/4650 [53:15<46:11:16, 36.45s/it]  2%|▏         | 89/4650 [53:51<46:08:20, 36.42s/it]                                                    {'loss': 0.6, 'learning_rate': 4.294732073706415e-05, 'epoch': 0.1}
  2%|▏         | 89/4650 [53:51<46:08:20, 36.42s/it]  2%|▏         | 90/4650 [54:27<46:09:18, 36.44s/it]                                                    {'loss': 0.8366, 'learning_rate': 4.3054226996549803e-05, 'epoch': 0.1}
  2%|▏         | 90/4650 [54:27<46:09:18, 36.44s/it]  2%|▏         | 91/4650 [55:04<46:06:44, 36.41s/it]                                                    {'loss': 0.6083, 'learning_rate': 4.315995194722688e-05, 'epoch': 0.1}
  2%|▏         | 91/4650 [55:04<46:06:44, 36.41s/it]  2%|▏         | 92/4650 [55:40<46:05:41, 36.41s/it]                                                    {'loss': 0.4897, 'learning_rate': 4.32645214108326e-05, 'epoch': 0.1}
  2%|▏         | 92/4650 [55:40<46:05:41, 36.41s/it]  2%|▏         | 93/4650 [56:17<46:04:53, 36.40s/it]                                                    {'loss': 0.5156, 'learning_rate': 4.3367960371609217e-05, 'epoch': 0.1}
  2%|▏         | 93/4650 [56:17<46:04:53, 36.40s/it]  2%|▏         | 94/4650 [56:53<46:04:53, 36.41s/it]                                                    {'loss': 0.7434, 'learning_rate': 4.347029301213452e-05, 'epoch': 0.1}
  2%|▏         | 94/4650 [56:53<46:04:53, 36.41s/it]  2%|▏         | 95/4650 [57:30<46:06:43, 36.44s/it]                                                    {'loss': 0.5318, 'learning_rate': 4.357154274725627e-05, 'epoch': 0.1}
  2%|▏         | 95/4650 [57:30<46:06:43, 36.44s/it]  2%|▏         | 96/4650 [58:06<46:06:41, 36.45s/it]                                                    {'loss': 0.6485, 'learning_rate': 4.367173225624997e-05, 'epoch': 0.1}
  2%|▏         | 96/4650 [58:06<46:06:41, 36.45s/it]  2%|▏         | 97/4650 [58:42<46:05:51, 36.45s/it]                                                    {'loss': 0.6014, 'learning_rate': 4.3770883513310265e-05, 'epoch': 0.1}
  2%|▏         | 97/4650 [58:42<46:05:51, 36.45s/it]  2%|▏         | 98/4650 [59:19<46:05:41, 36.45s/it]                                                    {'loss': 0.4492, 'learning_rate': 4.3869017816478676e-05, 'epoch': 0.11}
  2%|▏         | 98/4650 [59:19<46:05:41, 36.45s/it]  2%|▏         | 99/4650 [59:55<46:04:53, 36.45s/it]                                                    {'loss': 0.6686, 'learning_rate': 4.396615581510274e-05, 'epoch': 0.11}
  2%|▏         | 99/4650 [59:55<46:04:53, 36.45s/it]  2%|▏         | 100/4650 [1:00:32<46:02:13, 36.43s/it]                                                       {'loss': 0.5088, 'learning_rate': 4.406231753591537e-05, 'epoch': 0.11}
  2%|▏         | 100/4650 [1:00:32<46:02:13, 36.43s/it]  2%|▏         | 101/4650 [1:01:08<46:00:27, 36.41s/it]                                                       {'loss': 0.3867, 'learning_rate': 4.415752240781645e-05, 'epoch': 0.11}
  2%|▏         | 101/4650 [1:01:08<46:00:27, 36.41s/it]  2%|▏         | 102/4650 [1:01:45<46:01:55, 36.44s/it]                                                       {'loss': 0.8627, 'learning_rate': 4.425178928543387e-05, 'epoch': 0.11}
  2%|▏         | 102/4650 [1:01:45<46:01:55, 36.44s/it]  2%|▏         | 103/4650 [1:02:21<46:02:38, 36.45s/it]                                                       {'loss': 0.6555, 'learning_rate': 4.4345136471534956e-05, 'epoch': 0.11}
  2%|▏         | 103/4650 [1:02:21<46:02:38, 36.45s/it]  2%|▏         | 104/4650 [1:02:58<46:04:15, 36.48s/it]                                                       {'loss': 0.8107, 'learning_rate': 4.4437581738355284e-05, 'epoch': 0.11}
  2%|▏         | 104/4650 [1:02:58<46:04:15, 36.48s/it]  2%|▏         | 105/4650 [1:03:34<46:00:51, 36.45s/it]                                                       {'loss': 0.4597, 'learning_rate': 4.4529142347906906e-05, 'epoch': 0.11}
  2%|▏         | 105/4650 [1:03:34<46:00:51, 36.45s/it]  2%|▏         | 106/4650 [1:04:10<46:00:45, 36.45s/it]                                                       {'loss': 0.6382, 'learning_rate': 4.4619835071324055e-05, 'epoch': 0.11}
  2%|▏         | 106/4650 [1:04:10<46:00:45, 36.45s/it]  2%|▏         | 107/4650 [1:04:47<45:59:37, 36.45s/it]                                                       {'loss': 0.518, 'learning_rate': 4.4709676207300585e-05, 'epoch': 0.11}
  2%|▏         | 107/4650 [1:04:47<45:59:37, 36.45s/it]  2%|▏         | 108/4650 [1:05:23<45:57:56, 36.43s/it]                                                       {'loss': 0.4867, 'learning_rate': 4.479868159966975e-05, 'epoch': 0.12}
  2%|▏         | 108/4650 [1:05:23<45:57:56, 36.43s/it]  2%|▏         | 109/4650 [1:06:00<45:58:25, 36.45s/it]                                                       {'loss': 0.7104, 'learning_rate': 4.488686665417388e-05, 'epoch': 0.12}
  2%|▏         | 109/4650 [1:06:00<45:58:25, 36.45s/it]  2%|▏         | 110/4650 [1:06:36<45:57:25, 36.44s/it]                                                       {'loss': 0.5899, 'learning_rate': 4.4974246354468306e-05, 'epoch': 0.12}
  2%|▏         | 110/4650 [1:06:36<45:57:25, 36.44s/it]  2%|▏         | 111/4650 [1:07:13<45:55:09, 36.42s/it]                                                       {'loss': 0.6379, 'learning_rate': 4.506083527740099e-05, 'epoch': 0.12}
  2%|▏         | 111/4650 [1:07:13<45:55:09, 36.42s/it]  2%|▏         | 112/4650 [1:07:49<46:00:35, 36.50s/it]                                                       {'loss': 0.6558, 'learning_rate': 4.514664760760707e-05, 'epoch': 0.12}
  2%|▏         | 112/4650 [1:07:49<46:00:35, 36.50s/it]  2%|▏         | 113/4650 [1:08:26<45:58:19, 36.48s/it]                                                       {'loss': 0.5753, 'learning_rate': 4.5231697151454656e-05, 'epoch': 0.12}
  2%|▏         | 113/4650 [1:08:26<45:58:19, 36.48s/it]  2%|▏         | 114/4650 [1:09:02<45:57:56, 36.48s/it]                                                       {'loss': 0.4822, 'learning_rate': 4.531599735037622e-05, 'epoch': 0.12}
  2%|▏         | 114/4650 [1:09:02<45:57:56, 36.48s/it]  2%|▏         | 115/4650 [1:09:39<45:57:20, 36.48s/it]                                                       {'loss': 0.4365, 'learning_rate': 4.539956129361793e-05, 'epoch': 0.12}
  2%|▏         | 115/4650 [1:09:39<45:57:20, 36.48s/it]  2%|▏         | 116/4650 [1:10:15<45:55:47, 36.47s/it]                                                       {'loss': 0.5824, 'learning_rate': 4.548240173043691e-05, 'epoch': 0.12}
  2%|▏         | 116/4650 [1:10:15<45:55:47, 36.47s/it]  3%|▎         | 117/4650 [1:10:51<45:51:47, 36.42s/it]                                                       {'loss': 0.666, 'learning_rate': 4.5564531081775067e-05, 'epoch': 0.13}
  3%|▎         | 117/4650 [1:10:51<45:51:47, 36.42s/it]  3%|▎         | 118/4650 [1:11:28<45:50:20, 36.41s/it]                                                       {'loss': 0.7523, 'learning_rate': 4.5645961451436106e-05, 'epoch': 0.13}
  3%|▎         | 118/4650 [1:11:28<45:50:20, 36.41s/it]  3%|▎         | 119/4650 [1:12:04<45:48:50, 36.40s/it]                                                       {'loss': 0.5947, 'learning_rate': 4.572670463679098e-05, 'epoch': 0.13}
  3%|▎         | 119/4650 [1:12:04<45:48:50, 36.40s/it]  3%|▎         | 120/4650 [1:12:41<45:46:41, 36.38s/it]                                                       {'loss': 0.4394, 'learning_rate': 4.58067721390353e-05, 'epoch': 0.13}
  3%|▎         | 120/4650 [1:12:41<45:46:41, 36.38s/it]  3%|▎         | 121/4650 [1:13:17<45:43:07, 36.34s/it]                                                       {'loss': 0.4186, 'learning_rate': 4.5886175173021244e-05, 'epoch': 0.13}
  3%|▎         | 121/4650 [1:13:17<45:43:07, 36.34s/it]  3%|▎         | 122/4650 [1:13:53<45:43:39, 36.36s/it]                                                       {'loss': 0.4392, 'learning_rate': 4.5964924676684684e-05, 'epoch': 0.13}
  3%|▎         | 122/4650 [1:13:53<45:43:39, 36.36s/it]  3%|▎         | 123/4650 [1:14:29<45:42:09, 36.34s/it]                                                       {'loss': 0.5264, 'learning_rate': 4.604303132008766e-05, 'epoch': 0.13}
  3%|▎         | 123/4650 [1:14:29<45:42:09, 36.34s/it]  3%|▎         | 124/4650 [1:15:06<45:40:41, 36.33s/it]                                                       {'loss': 0.4402, 'learning_rate': 4.612050551409472e-05, 'epoch': 0.13}
  3%|▎         | 124/4650 [1:15:06<45:40:41, 36.33s/it]  3%|▎         | 125/4650 [1:15:42<45:37:18, 36.30s/it]                                                       {'loss': 0.5912, 'learning_rate': 4.619735741870071e-05, 'epoch': 0.13}
  3%|▎         | 125/4650 [1:15:42<45:37:18, 36.30s/it]  3%|▎         | 126/4650 [1:16:18<45:36:30, 36.29s/it]                                                       {'loss': 0.611, 'learning_rate': 4.627359695102685e-05, 'epoch': 0.14}
  3%|▎         | 126/4650 [1:16:18<45:36:30, 36.29s/it]  3%|▎         | 127/4650 [1:16:55<45:36:55, 36.31s/it]                                                       {'loss': 0.6793, 'learning_rate': 4.634923379300082e-05, 'epoch': 0.14}
  3%|▎         | 127/4650 [1:16:55<45:36:55, 36.31s/it]  3%|▎         | 128/4650 [1:17:31<45:34:23, 36.28s/it]                                                       {'loss': 0.6571, 'learning_rate': 4.6424277398735474e-05, 'epoch': 0.14}
  3%|▎         | 128/4650 [1:17:31<45:34:23, 36.28s/it]  3%|▎         | 129/4650 [1:18:07<45:35:03, 36.30s/it]                                                       {'loss': 0.6869, 'learning_rate': 4.649873700162056e-05, 'epoch': 0.14}
  3%|▎         | 129/4650 [1:18:07<45:35:03, 36.30s/it]  3%|▎         | 130/4650 [1:18:44<45:35:53, 36.32s/it]                                                       {'loss': 0.4893, 'learning_rate': 4.657262162114062e-05, 'epoch': 0.14}
  3%|▎         | 130/4650 [1:18:44<45:35:53, 36.32s/it]  3%|▎         | 131/4650 [1:19:20<45:33:55, 36.30s/it]                                                       {'loss': 0.3042, 'learning_rate': 4.664594006943161e-05, 'epoch': 0.14}
  3%|▎         | 131/4650 [1:19:20<45:33:55, 36.30s/it]  3%|▎         | 132/4650 [1:19:56<45:32:37, 36.29s/it]                                                       {'loss': 0.7308, 'learning_rate': 4.671870095758825e-05, 'epoch': 0.14}
  3%|▎         | 132/4650 [1:19:56<45:32:37, 36.29s/it]  3%|▎         | 133/4650 [1:20:32<45:29:58, 36.26s/it]                                                       {'loss': 0.4959, 'learning_rate': 4.679091270173332e-05, 'epoch': 0.14}
  3%|▎         | 133/4650 [1:20:32<45:29:58, 36.26s/it]  3%|▎         | 134/4650 [1:21:09<45:30:03, 36.27s/it]                                                       {'loss': 0.6644, 'learning_rate': 4.6862583528859686e-05, 'epoch': 0.14}
  3%|▎         | 134/4650 [1:21:09<45:30:03, 36.27s/it]  3%|▎         | 135/4650 [1:21:45<45:29:37, 36.27s/it]                                                       {'loss': 0.3554, 'learning_rate': 4.6933721482455084e-05, 'epoch': 0.15}
  3%|▎         | 135/4650 [1:21:45<45:29:37, 36.27s/it]  3%|▎         | 136/4650 [1:22:21<45:29:25, 36.28s/it]                                                       {'loss': 0.5859, 'learning_rate': 4.7004334427919384e-05, 'epoch': 0.15}
  3%|▎         | 136/4650 [1:22:21<45:29:25, 36.28s/it]  3%|▎         | 137/4650 [1:22:57<45:28:43, 36.28s/it]                                                       {'loss': 0.6348, 'learning_rate': 4.707443005778338e-05, 'epoch': 0.15}
  3%|▎         | 137/4650 [1:22:57<45:28:43, 36.28s/it]  3%|▎         | 138/4650 [1:23:34<45:27:36, 36.27s/it]                                                       {'loss': 0.5582, 'learning_rate': 4.714401589673788e-05, 'epoch': 0.15}
  3%|▎         | 138/4650 [1:23:34<45:27:36, 36.27s/it]  3%|▎         | 139/4650 [1:24:10<45:26:10, 36.26s/it]                                                       {'loss': 0.4712, 'learning_rate': 4.7213099306481085e-05, 'epoch': 0.15}
  3%|▎         | 139/4650 [1:24:10<45:26:10, 36.26s/it]  3%|▎         | 140/4650 [1:24:46<45:30:29, 36.33s/it]                                                       {'loss': 0.5285, 'learning_rate': 4.7281687490392404e-05, 'epoch': 0.15}
  3%|▎         | 140/4650 [1:24:46<45:30:29, 36.33s/it]  3%|▎         | 141/4650 [1:25:23<45:27:26, 36.29s/it]                                                       {'loss': 0.4441, 'learning_rate': 4.7349787498039804e-05, 'epoch': 0.15}
  3%|▎         | 141/4650 [1:25:23<45:27:26, 36.29s/it]  3%|▎         | 142/4650 [1:25:59<45:25:09, 36.27s/it]                                                       {'loss': 0.6888, 'learning_rate': 4.74174062295279e-05, 'epoch': 0.15}
  3%|▎         | 142/4650 [1:25:59<45:25:09, 36.27s/it]  3%|▎         | 143/4650 [1:26:35<45:23:58, 36.26s/it]                                                       {'loss': 0.5688, 'learning_rate': 4.748455043969356e-05, 'epoch': 0.15}
  3%|▎         | 143/4650 [1:26:35<45:23:58, 36.26s/it]  3%|▎         | 144/4650 [1:27:11<45:26:20, 36.30s/it]                                                       {'loss': 0.4775, 'learning_rate': 4.755122674215525e-05, 'epoch': 0.15}
  3%|▎         | 144/4650 [1:27:11<45:26:20, 36.30s/it]  3%|▎         | 145/4650 [1:27:48<45:22:03, 36.25s/it]                                                       {'loss': 0.5688, 'learning_rate': 4.761744161322224e-05, 'epoch': 0.16}
  3%|▎         | 145/4650 [1:27:48<45:22:03, 36.25s/it]  3%|▎         | 146/4650 [1:28:24<45:24:27, 36.29s/it]                                                       {'loss': 0.62, 'learning_rate': 4.768320139566955e-05, 'epoch': 0.16}
  3%|▎         | 146/4650 [1:28:24<45:24:27, 36.29s/it]  3%|▎         | 147/4650 [1:29:00<45:21:45, 36.27s/it]                                                       {'loss': 0.5597, 'learning_rate': 4.774851230238395e-05, 'epoch': 0.16}
  3%|▎         | 147/4650 [1:29:00<45:21:45, 36.27s/it]  3%|▎         | 148/4650 [1:29:36<45:21:42, 36.27s/it]                                                       {'loss': 0.6573, 'learning_rate': 4.781338041988649e-05, 'epoch': 0.16}
  3%|▎         | 148/4650 [1:29:36<45:21:42, 36.27s/it]  3%|▎         | 149/4650 [1:30:13<45:20:44, 36.27s/it]                                                       {'loss': 0.6611, 'learning_rate': 4.787781171173631e-05, 'epoch': 0.16}
  3%|▎         | 149/4650 [1:30:13<45:20:44, 36.27s/it]  3%|▎         | 150/4650 [1:30:49<45:20:32, 36.27s/it]                                                       {'loss': 0.3617, 'learning_rate': 4.794181202182064e-05, 'epoch': 0.16}
  3%|▎         | 150/4650 [1:30:49<45:20:32, 36.27s/it]  3%|▎         | 151/4650 [1:31:25<45:17:26, 36.24s/it]                                                       {'loss': 0.5185, 'learning_rate': 4.800538707753558e-05, 'epoch': 0.16}
  3%|▎         | 151/4650 [1:31:25<45:17:26, 36.24s/it]  3%|▎         | 152/4650 [1:32:01<45:16:35, 36.24s/it]                                                       {'loss': 0.3937, 'learning_rate': 4.806854249286172e-05, 'epoch': 0.16}
  3%|▎         | 152/4650 [1:32:01<45:16:35, 36.24s/it]  3%|▎         | 153/4650 [1:32:38<45:17:09, 36.25s/it]                                                       {'loss': 0.5211, 'learning_rate': 4.8131283771339154e-05, 'epoch': 0.16}
  3%|▎         | 153/4650 [1:32:38<45:17:09, 36.25s/it]  3%|▎         | 154/4650 [1:33:14<45:17:03, 36.26s/it]                                                       {'loss': 0.8307, 'learning_rate': 4.8193616308945356e-05, 'epoch': 0.17}
  3%|▎         | 154/4650 [1:33:14<45:17:03, 36.26s/it]  3%|▎         | 155/4650 [1:33:50<45:15:26, 36.25s/it]                                                       {'loss': 0.5902, 'learning_rate': 4.825554539688006e-05, 'epoch': 0.17}
  3%|▎         | 155/4650 [1:33:50<45:15:26, 36.25s/it]  3%|▎         | 156/4650 [1:34:26<45:13:53, 36.23s/it]                                                       {'loss': 0.3858, 'learning_rate': 4.8317076224260565e-05, 'epoch': 0.17}
  3%|▎         | 156/4650 [1:34:26<45:13:53, 36.23s/it]  3%|▎         | 157/4650 [1:35:03<45:11:29, 36.21s/it]                                                       {'loss': 0.6192, 'learning_rate': 4.837821388073091e-05, 'epoch': 0.17}
  3%|▎         | 157/4650 [1:35:03<45:11:29, 36.21s/it]  3%|▎         | 158/4650 [1:35:39<45:09:56, 36.20s/it]                                                       {'loss': 0.588, 'learning_rate': 4.843896335898822e-05, 'epoch': 0.17}
  3%|▎         | 158/4650 [1:35:39<45:09:56, 36.20s/it]  3%|▎         | 159/4650 [1:36:15<45:09:21, 36.20s/it]                                                       {'loss': 0.504, 'learning_rate': 4.8499329557229336e-05, 'epoch': 0.17}
  3%|▎         | 159/4650 [1:36:15<45:09:21, 36.20s/it]  3%|▎         | 160/4650 [1:36:51<45:07:38, 36.18s/it]                                                       {'loss': 0.4301, 'learning_rate': 4.8559317281520806e-05, 'epoch': 0.17}
  3%|▎         | 160/4650 [1:36:51<45:07:38, 36.18s/it]  3%|▎         | 161/4650 [1:37:27<45:06:56, 36.18s/it]                                                       {'loss': 0.6958, 'learning_rate': 4.8618931248094976e-05, 'epoch': 0.17}
  3%|▎         | 161/4650 [1:37:27<45:06:56, 36.18s/it]  3%|▎         | 162/4650 [1:38:03<45:06:40, 36.19s/it]                                                       {'loss': 0.601, 'learning_rate': 4.8678176085575026e-05, 'epoch': 0.17}
  3%|▎         | 162/4650 [1:38:04<45:06:40, 36.19s/it]  4%|▎         | 163/4650 [1:38:40<45:07:41, 36.21s/it]                                                       {'loss': 0.3695, 'learning_rate': 4.873705633713155e-05, 'epoch': 0.18}
  4%|▎         | 163/4650 [1:38:40<45:07:41, 36.21s/it]  4%|▎         | 164/4650 [1:39:16<45:06:50, 36.20s/it]                                                       {'loss': 0.4916, 'learning_rate': 4.8795576462573175e-05, 'epoch': 0.18}
  4%|▎         | 164/4650 [1:39:16<45:06:50, 36.20s/it]  4%|▎         | 165/4650 [1:39:52<45:04:09, 36.18s/it]                                                       {'loss': 0.6233, 'learning_rate': 4.885374084037358e-05, 'epoch': 0.18}
  4%|▎         | 165/4650 [1:39:52<45:04:09, 36.18s/it]  4%|▎         | 166/4650 [1:40:28<45:03:07, 36.17s/it]                                                       {'loss': 0.5414, 'learning_rate': 4.891155376963743e-05, 'epoch': 0.18}
  4%|▎         | 166/4650 [1:40:28<45:03:07, 36.17s/it]  4%|▎         | 167/4650 [1:41:04<45:03:05, 36.18s/it]                                                       {'loss': 0.6383, 'learning_rate': 4.896901947200704e-05, 'epoch': 0.18}
  4%|▎         | 167/4650 [1:41:04<45:03:05, 36.18s/it]  4%|▎         | 168/4650 [1:41:41<45:03:11, 36.19s/it]                                                       {'loss': 0.3458, 'learning_rate': 4.902614209351235e-05, 'epoch': 0.18}
  4%|▎         | 168/4650 [1:41:41<45:03:11, 36.19s/it]  4%|▎         | 169/4650 [1:42:17<45:01:26, 36.17s/it]                                                       {'loss': 0.6249, 'learning_rate': 4.908292570636588e-05, 'epoch': 0.18}
  4%|▎         | 169/4650 [1:42:17<45:01:26, 36.17s/it]  4%|▎         | 170/4650 [1:42:53<44:59:28, 36.15s/it]                                                       {'loss': 0.5579, 'learning_rate': 4.913937431070472e-05, 'epoch': 0.18}
  4%|▎         | 170/4650 [1:42:53<44:59:28, 36.15s/it]  4%|▎         | 171/4650 [1:43:29<44:59:12, 36.16s/it]                                                       {'loss': 0.5716, 'learning_rate': 4.9195491836281506e-05, 'epoch': 0.18}
  4%|▎         | 171/4650 [1:43:29<44:59:12, 36.16s/it]  4%|▎         | 172/4650 [1:44:05<44:57:46, 36.15s/it]                                                       {'loss': 0.4257, 'learning_rate': 4.925128214410606e-05, 'epoch': 0.18}
  4%|▎         | 172/4650 [1:44:05<44:57:46, 36.15s/it]  4%|▎         | 173/4650 [1:44:41<44:57:07, 36.15s/it]                                                       {'loss': 0.578, 'learning_rate': 4.930674902803948e-05, 'epoch': 0.19}
  4%|▎         | 173/4650 [1:44:41<44:57:07, 36.15s/it]  4%|▎         | 174/4650 [1:45:17<44:56:40, 36.15s/it]                                                       {'loss': 0.4257, 'learning_rate': 4.936189621634219e-05, 'epoch': 0.19}
  4%|▎         | 174/4650 [1:45:17<44:56:40, 36.15s/it]  4%|▍         | 175/4650 [1:45:54<44:57:43, 36.17s/it]                                                       {'loss': 0.676, 'learning_rate': 4.9416727373177744e-05, 'epoch': 0.19}
  4%|▍         | 175/4650 [1:45:54<44:57:43, 36.17s/it]  4%|▍         | 176/4650 [1:46:30<44:55:57, 36.15s/it]                                                       {'loss': 0.596, 'learning_rate': 4.9471246100073745e-05, 'epoch': 0.19}
  4%|▍         | 176/4650 [1:46:30<44:55:57, 36.15s/it]  4%|▍         | 177/4650 [1:47:06<44:54:27, 36.14s/it]                                                       {'loss': 0.4124, 'learning_rate': 4.952545593734138e-05, 'epoch': 0.19}
  4%|▍         | 177/4650 [1:47:06<44:54:27, 36.14s/it]  4%|▍         | 178/4650 [1:47:42<44:53:37, 36.14s/it]                                                       {'loss': 0.5095, 'learning_rate': 4.957936036545493e-05, 'epoch': 0.19}
  4%|▍         | 178/4650 [1:47:42<44:53:37, 36.14s/it]  4%|▍         | 179/4650 [1:48:18<44:52:39, 36.13s/it]                                                       {'loss': 0.571, 'learning_rate': 4.963296280639271e-05, 'epoch': 0.19}
  4%|▍         | 179/4650 [1:48:18<44:52:39, 36.13s/it]  4%|▍         | 180/4650 [1:48:54<44:55:10, 36.18s/it]                                                       {'loss': 0.5434, 'learning_rate': 4.968626662494059e-05, 'epoch': 0.19}
  4%|▍         | 180/4650 [1:48:54<44:55:10, 36.18s/it]  4%|▍         | 181/4650 [1:49:31<44:54:02, 36.17s/it]                                                       {'loss': 0.5338, 'learning_rate': 4.9739275129959437e-05, 'epoch': 0.19}
  4%|▍         | 181/4650 [1:49:31<44:54:02, 36.17s/it]  4%|▍         | 182/4650 [1:50:07<44:53:02, 36.16s/it]                                                       {'loss': 0.3581, 'learning_rate': 4.979199157561766e-05, 'epoch': 0.2}
  4%|▍         | 182/4650 [1:50:07<44:53:02, 36.16s/it]  4%|▍         | 183/4650 [1:50:43<44:51:02, 36.15s/it]                                                       {'loss': 0.5175, 'learning_rate': 4.9844419162589965e-05, 'epoch': 0.2}
  4%|▍         | 183/4650 [1:50:43<44:51:02, 36.15s/it]  4%|▍         | 184/4650 [1:51:19<44:50:34, 36.15s/it]                                                       {'loss': 0.538, 'learning_rate': 4.989656103922338e-05, 'epoch': 0.2}
  4%|▍         | 184/4650 [1:51:19<44:50:34, 36.15s/it]  4%|▍         | 185/4650 [1:51:55<44:49:46, 36.14s/it]                                                       {'loss': 0.6458, 'learning_rate': 4.994842030267182e-05, 'epoch': 0.2}
  4%|▍         | 185/4650 [1:51:55<44:49:46, 36.14s/it]  4%|▍         | 186/4650 [1:52:31<44:48:59, 36.14s/it]                                                       {'loss': 0.5376, 'learning_rate': 5e-05, 'epoch': 0.2}
  4%|▍         | 186/4650 [1:52:31<44:48:59, 36.14s/it]  4%|▍         | 187/4650 [1:53:07<44:48:56, 36.15s/it]                                                       {'loss': 0.4936, 'learning_rate': 5e-05, 'epoch': 0.2}
  4%|▍         | 187/4650 [1:53:07<44:48:56, 36.15s/it]  4%|▍         | 188/4650 [1:53:44<44:49:03, 36.16s/it]                                                       {'loss': 0.4854, 'learning_rate': 5e-05, 'epoch': 0.2}
  4%|▍         | 188/4650 [1:53:44<44:49:03, 36.16s/it]  4%|▍         | 189/4650 [1:54:20<44:47:36, 36.15s/it]                                                       {'loss': 0.6181, 'learning_rate': 5e-05, 'epoch': 0.2}
  4%|▍         | 189/4650 [1:54:20<44:47:36, 36.15s/it]  4%|▍         | 190/4650 [1:54:56<44:48:33, 36.17s/it]                                                       {'loss': 0.4259, 'learning_rate': 5e-05, 'epoch': 0.2}
  4%|▍         | 190/4650 [1:54:56<44:48:33, 36.17s/it]  4%|▍         | 191/4650 [1:55:32<44:47:51, 36.17s/it]                                                       {'loss': 0.6003, 'learning_rate': 5e-05, 'epoch': 0.21}
  4%|▍         | 191/4650 [1:55:32<44:47:51, 36.17s/it]  4%|▍         | 192/4650 [1:56:08<44:47:14, 36.17s/it]                                                       {'loss': 0.7456, 'learning_rate': 5e-05, 'epoch': 0.21}
  4%|▍         | 192/4650 [1:56:08<44:47:14, 36.17s/it]  4%|▍         | 193/4650 [1:56:44<44:45:45, 36.16s/it]                                                       {'loss': 0.2774, 'learning_rate': 5e-05, 'epoch': 0.21}
  4%|▍         | 193/4650 [1:56:44<44:45:45, 36.16s/it]  4%|▍         | 194/4650 [1:57:21<44:45:40, 36.16s/it]                                                       {'loss': 0.7137, 'learning_rate': 5e-05, 'epoch': 0.21}
  4%|▍         | 194/4650 [1:57:21<44:45:40, 36.16s/it]  4%|▍         | 195/4650 [1:57:57<44:44:14, 36.15s/it]                                                       {'loss': 0.5404, 'learning_rate': 5e-05, 'epoch': 0.21}
  4%|▍         | 195/4650 [1:57:57<44:44:14, 36.15s/it]  4%|▍         | 196/4650 [1:58:33<44:43:16, 36.15s/it]                                                       {'loss': 0.7159, 'learning_rate': 5e-05, 'epoch': 0.21}
  4%|▍         | 196/4650 [1:58:33<44:43:16, 36.15s/it]  4%|▍         | 197/4650 [1:59:09<44:44:11, 36.17s/it]                                                       {'loss': 0.6315, 'learning_rate': 5e-05, 'epoch': 0.21}
  4%|▍         | 197/4650 [1:59:09<44:44:11, 36.17s/it]  4%|▍         | 198/4650 [1:59:45<44:43:11, 36.16s/it]                                                       {'loss': 0.5612, 'learning_rate': 5e-05, 'epoch': 0.21}
  4%|▍         | 198/4650 [1:59:45<44:43:11, 36.16s/it]  4%|▍         | 199/4650 [2:00:21<44:42:33, 36.16s/it]                                                       {'loss': 0.7282, 'learning_rate': 5e-05, 'epoch': 0.21}
  4%|▍         | 199/4650 [2:00:21<44:42:33, 36.16s/it]  4%|▍         | 200/4650 [2:00:58<44:43:04, 36.18s/it]                                                       {'loss': 0.4927, 'learning_rate': 5e-05, 'epoch': 0.21}
  4%|▍         | 200/4650 [2:00:58<44:43:04, 36.18s/it]  4%|▍         | 201/4650 [2:01:34<44:40:56, 36.16s/it]                                                       {'loss': 0.5154, 'learning_rate': 5e-05, 'epoch': 0.22}
  4%|▍         | 201/4650 [2:01:34<44:40:56, 36.16s/it]  4%|▍         | 202/4650 [2:02:10<44:40:09, 36.15s/it]                                                       {'loss': 0.448, 'learning_rate': 5e-05, 'epoch': 0.22}
  4%|▍         | 202/4650 [2:02:10<44:40:09, 36.15s/it]  4%|▍         | 203/4650 [2:02:46<44:40:15, 36.16s/it]                                                       {'loss': 0.6594, 'learning_rate': 5e-05, 'epoch': 0.22}
  4%|▍         | 203/4650 [2:02:46<44:40:15, 36.16s/it]  4%|▍         | 204/4650 [2:03:22<44:39:27, 36.16s/it]                                                       {'loss': 0.4342, 'learning_rate': 5e-05, 'epoch': 0.22}
  4%|▍         | 204/4650 [2:03:22<44:39:27, 36.16s/it]  4%|▍         | 205/4650 [2:03:58<44:38:50, 36.16s/it]                                                       {'loss': 0.4946, 'learning_rate': 5e-05, 'epoch': 0.22}
  4%|▍         | 205/4650 [2:03:58<44:38:50, 36.16s/it]  4%|▍         | 206/4650 [2:04:34<44:38:06, 36.16s/it]                                                       {'loss': 0.6413, 'learning_rate': 5e-05, 'epoch': 0.22}
  4%|▍         | 206/4650 [2:04:34<44:38:06, 36.16s/it]  4%|▍         | 207/4650 [2:05:11<44:38:31, 36.17s/it]                                                       {'loss': 0.6134, 'learning_rate': 5e-05, 'epoch': 0.22}
  4%|▍         | 207/4650 [2:05:11<44:38:31, 36.17s/it]  4%|▍         | 208/4650 [2:05:47<44:38:08, 36.17s/it]                                                       {'loss': 0.5651, 'learning_rate': 5e-05, 'epoch': 0.22}
  4%|▍         | 208/4650 [2:05:47<44:38:08, 36.17s/it]  4%|▍         | 209/4650 [2:06:23<44:36:43, 36.16s/it]                                                       {'loss': 0.3882, 'learning_rate': 5e-05, 'epoch': 0.22}
  4%|▍         | 209/4650 [2:06:23<44:36:43, 36.16s/it]  5%|▍         | 210/4650 [2:06:59<44:35:30, 36.16s/it]                                                       {'loss': 0.3021, 'learning_rate': 5e-05, 'epoch': 0.23}
  5%|▍         | 210/4650 [2:06:59<44:35:30, 36.16s/it]  5%|▍         | 211/4650 [2:07:35<44:34:01, 36.14s/it]                                                       {'loss': 0.4735, 'learning_rate': 5e-05, 'epoch': 0.23}
  5%|▍         | 211/4650 [2:07:35<44:34:01, 36.14s/it]  5%|▍         | 212/4650 [2:08:11<44:33:58, 36.15s/it]                                                       {'loss': 0.8316, 'learning_rate': 5e-05, 'epoch': 0.23}
  5%|▍         | 212/4650 [2:08:11<44:33:58, 36.15s/it]  5%|▍         | 213/4650 [2:08:48<44:33:09, 36.15s/it]                                                       {'loss': 0.4807, 'learning_rate': 5e-05, 'epoch': 0.23}
  5%|▍         | 213/4650 [2:08:48<44:33:09, 36.15s/it]  5%|▍         | 214/4650 [2:09:24<44:35:28, 36.19s/it]                                                       {'loss': 0.5415, 'learning_rate': 5e-05, 'epoch': 0.23}
  5%|▍         | 214/4650 [2:09:24<44:35:28, 36.19s/it]  5%|▍         | 215/4650 [2:10:00<44:34:03, 36.18s/it]                                                       {'loss': 0.484, 'learning_rate': 5e-05, 'epoch': 0.23}
  5%|▍         | 215/4650 [2:10:00<44:34:03, 36.18s/it]  5%|▍         | 216/4650 [2:10:36<44:34:22, 36.19s/it]                                                       {'loss': 0.4596, 'learning_rate': 5e-05, 'epoch': 0.23}
  5%|▍         | 216/4650 [2:10:36<44:34:22, 36.19s/it]  5%|▍         | 217/4650 [2:11:13<44:38:57, 36.26s/it]                                                       {'loss': 0.4749, 'learning_rate': 5e-05, 'epoch': 0.23}
  5%|▍         | 217/4650 [2:11:13<44:38:57, 36.26s/it]  5%|▍         | 218/4650 [2:11:49<44:42:54, 36.32s/it]                                                       {'loss': 0.454, 'learning_rate': 5e-05, 'epoch': 0.23}
  5%|▍         | 218/4650 [2:11:49<44:42:54, 36.32s/it]  5%|▍         | 219/4650 [2:12:25<44:42:09, 36.32s/it]                                                       {'loss': 0.2678, 'learning_rate': 5e-05, 'epoch': 0.24}
  5%|▍         | 219/4650 [2:12:25<44:42:09, 36.32s/it]  5%|▍         | 220/4650 [2:13:02<44:40:56, 36.31s/it]                                                       {'loss': 0.5301, 'learning_rate': 5e-05, 'epoch': 0.24}
  5%|▍         | 220/4650 [2:13:02<44:40:56, 36.31s/it]  5%|▍         | 221/4650 [2:13:38<44:43:00, 36.35s/it]                                                       {'loss': 0.5371, 'learning_rate': 5e-05, 'epoch': 0.24}
  5%|▍         | 221/4650 [2:13:38<44:43:00, 36.35s/it]  5%|▍         | 222/4650 [2:14:15<44:45:30, 36.39s/it]                                                       {'loss': 0.4833, 'learning_rate': 5e-05, 'epoch': 0.24}
  5%|▍         | 222/4650 [2:14:15<44:45:30, 36.39s/it]  5%|▍         | 223/4650 [2:14:51<44:41:22, 36.34s/it]                                                       {'loss': 0.4049, 'learning_rate': 5e-05, 'epoch': 0.24}
  5%|▍         | 223/4650 [2:14:51<44:41:22, 36.34s/it]  5%|▍         | 224/4650 [2:15:27<44:38:18, 36.31s/it]                                                       {'loss': 0.6786, 'learning_rate': 5e-05, 'epoch': 0.24}
  5%|▍         | 224/4650 [2:15:27<44:38:18, 36.31s/it]  5%|▍         | 225/4650 [2:16:03<44:38:28, 36.32s/it]                                                       {'loss': 0.464, 'learning_rate': 5e-05, 'epoch': 0.24}
  5%|▍         | 225/4650 [2:16:03<44:38:28, 36.32s/it]  5%|▍         | 226/4650 [2:16:40<44:38:02, 36.32s/it]                                                       {'loss': 0.4615, 'learning_rate': 5e-05, 'epoch': 0.24}
  5%|▍         | 226/4650 [2:16:40<44:38:02, 36.32s/it]  5%|▍         | 227/4650 [2:17:16<44:37:25, 36.32s/it]                                                       {'loss': 0.3354, 'learning_rate': 5e-05, 'epoch': 0.24}
  5%|▍         | 227/4650 [2:17:16<44:37:25, 36.32s/it]  5%|▍         | 228/4650 [2:17:52<44:37:19, 36.33s/it]                                                       {'loss': 0.4442, 'learning_rate': 5e-05, 'epoch': 0.25}
  5%|▍         | 228/4650 [2:17:52<44:37:19, 36.33s/it]  5%|▍         | 229/4650 [2:18:29<44:38:42, 36.35s/it]                                                       {'loss': 0.6814, 'learning_rate': 5e-05, 'epoch': 0.25}
  5%|▍         | 229/4650 [2:18:29<44:38:42, 36.35s/it]  5%|▍         | 230/4650 [2:19:05<44:39:14, 36.37s/it]                                                       {'loss': 0.5567, 'learning_rate': 5e-05, 'epoch': 0.25}
  5%|▍         | 230/4650 [2:19:05<44:39:14, 36.37s/it]  5%|▍         | 231/4650 [2:19:42<44:39:53, 36.39s/it]                                                       {'loss': 0.4582, 'learning_rate': 5e-05, 'epoch': 0.25}
  5%|▍         | 231/4650 [2:19:42<44:39:53, 36.39s/it]  5%|▍         | 232/4650 [2:20:18<44:40:20, 36.40s/it]                                                       {'loss': 0.3465, 'learning_rate': 5e-05, 'epoch': 0.25}
  5%|▍         | 232/4650 [2:20:18<44:40:20, 36.40s/it]  5%|▌         | 233/4650 [2:20:54<44:39:04, 36.39s/it]                                                       {'loss': 0.7287, 'learning_rate': 5e-05, 'epoch': 0.25}
  5%|▌         | 233/4650 [2:20:54<44:39:04, 36.39s/it]  5%|▌         | 234/4650 [2:21:31<44:37:48, 36.38s/it]                                                       {'loss': 0.4799, 'learning_rate': 5e-05, 'epoch': 0.25}
  5%|▌         | 234/4650 [2:21:31<44:37:48, 36.38s/it]  5%|▌         | 235/4650 [2:22:07<44:36:04, 36.37s/it]                                                       {'loss': 0.5651, 'learning_rate': 5e-05, 'epoch': 0.25}
  5%|▌         | 235/4650 [2:22:07<44:36:04, 36.37s/it]  5%|▌         | 236/4650 [2:22:44<44:36:00, 36.38s/it]                                                       {'loss': 0.4944, 'learning_rate': 5e-05, 'epoch': 0.25}
  5%|▌         | 236/4650 [2:22:44<44:36:00, 36.38s/it]  5%|▌         | 237/4650 [2:23:20<44:37:01, 36.40s/it]                                                       {'loss': 0.5157, 'learning_rate': 5e-05, 'epoch': 0.25}
  5%|▌         | 237/4650 [2:23:20<44:37:01, 36.40s/it]  5%|▌         | 238/4650 [2:23:56<44:36:35, 36.40s/it]                                                       {'loss': 0.5711, 'learning_rate': 5e-05, 'epoch': 0.26}
  5%|▌         | 238/4650 [2:23:56<44:36:35, 36.40s/it]  5%|▌         | 239/4650 [2:24:33<44:36:29, 36.41s/it]                                                       {'loss': 0.5358, 'learning_rate': 5e-05, 'epoch': 0.26}
  5%|▌         | 239/4650 [2:24:33<44:36:29, 36.41s/it]  5%|▌         | 240/4650 [2:25:09<44:35:29, 36.40s/it]                                                       {'loss': 0.4872, 'learning_rate': 5e-05, 'epoch': 0.26}
  5%|▌         | 240/4650 [2:25:09<44:35:29, 36.40s/it]  5%|▌         | 241/4650 [2:25:46<44:35:55, 36.42s/it]                                                       {'loss': 0.6866, 'learning_rate': 5e-05, 'epoch': 0.26}
  5%|▌         | 241/4650 [2:25:46<44:35:55, 36.42s/it]  5%|▌         | 242/4650 [2:26:22<44:34:26, 36.40s/it]                                                       {'loss': 0.7072, 'learning_rate': 5e-05, 'epoch': 0.26}
  5%|▌         | 242/4650 [2:26:22<44:34:26, 36.40s/it]  5%|▌         | 243/4650 [2:26:58<44:33:07, 36.39s/it]                                                       {'loss': 0.4338, 'learning_rate': 5e-05, 'epoch': 0.26}
  5%|▌         | 243/4650 [2:26:58<44:33:07, 36.39s/it]  5%|▌         | 244/4650 [2:27:35<44:34:49, 36.43s/it]                                                       {'loss': 0.5303, 'learning_rate': 5e-05, 'epoch': 0.26}
  5%|▌         | 244/4650 [2:27:35<44:34:49, 36.43s/it]  5%|▌         | 245/4650 [2:28:11<44:32:56, 36.41s/it]                                                       {'loss': 0.7743, 'learning_rate': 5e-05, 'epoch': 0.26}
  5%|▌         | 245/4650 [2:28:11<44:32:56, 36.41s/it]  5%|▌         | 246/4650 [2:28:48<44:32:56, 36.42s/it]                                                       {'loss': 0.5392, 'learning_rate': 5e-05, 'epoch': 0.26}
  5%|▌         | 246/4650 [2:28:48<44:32:56, 36.42s/it]  5%|▌         | 247/4650 [2:29:24<44:32:49, 36.42s/it]                                                       {'loss': 0.7086, 'learning_rate': 5e-05, 'epoch': 0.27}
  5%|▌         | 247/4650 [2:29:24<44:32:49, 36.42s/it]  5%|▌         | 248/4650 [2:30:01<44:34:09, 36.45s/it]                                                       {'loss': 0.4744, 'learning_rate': 5e-05, 'epoch': 0.27}
  5%|▌         | 248/4650 [2:30:01<44:34:09, 36.45s/it]  5%|▌         | 249/4650 [2:30:37<44:31:12, 36.42s/it]                                                       {'loss': 0.4871, 'learning_rate': 5e-05, 'epoch': 0.27}
  5%|▌         | 249/4650 [2:30:37<44:31:12, 36.42s/it]  5%|▌         | 250/4650 [2:31:13<44:30:05, 36.41s/it]                                                       {'loss': 0.3556, 'learning_rate': 5e-05, 'epoch': 0.27}
  5%|▌         | 250/4650 [2:31:13<44:30:05, 36.41s/it]  5%|▌         | 251/4650 [2:31:50<44:29:26, 36.41s/it]                                                       {'loss': 0.5243, 'learning_rate': 5e-05, 'epoch': 0.27}
  5%|▌         | 251/4650 [2:31:50<44:29:26, 36.41s/it]  5%|▌         | 252/4650 [2:32:26<44:28:51, 36.41s/it]                                                       {'loss': 0.3131, 'learning_rate': 5e-05, 'epoch': 0.27}
  5%|▌         | 252/4650 [2:32:26<44:28:51, 36.41s/it]  5%|▌         | 253/4650 [2:33:03<44:29:42, 36.43s/it]                                                       {'loss': 0.4014, 'learning_rate': 5e-05, 'epoch': 0.27}
  5%|▌         | 253/4650 [2:33:03<44:29:42, 36.43s/it]  5%|▌         | 254/4650 [2:33:39<44:29:20, 36.43s/it]                                                       {'loss': 0.424, 'learning_rate': 5e-05, 'epoch': 0.27}
  5%|▌         | 254/4650 [2:33:39<44:29:20, 36.43s/it]  5%|▌         | 255/4650 [2:34:15<44:27:26, 36.42s/it]                                                       {'loss': 0.6421, 'learning_rate': 5e-05, 'epoch': 0.27}
  5%|▌         | 255/4650 [2:34:15<44:27:26, 36.42s/it]  6%|▌         | 256/4650 [2:34:52<44:28:00, 36.43s/it]                                                       {'loss': 0.3939, 'learning_rate': 5e-05, 'epoch': 0.28}
  6%|▌         | 256/4650 [2:34:52<44:28:00, 36.43s/it]  6%|▌         | 257/4650 [2:35:28<44:25:16, 36.40s/it]                                                       {'loss': 0.6419, 'learning_rate': 5e-05, 'epoch': 0.28}
  6%|▌         | 257/4650 [2:35:28<44:25:16, 36.40s/it]  6%|▌         | 258/4650 [2:36:05<44:25:01, 36.41s/it]                                                       {'loss': 0.4102, 'learning_rate': 5e-05, 'epoch': 0.28}
  6%|▌         | 258/4650 [2:36:05<44:25:01, 36.41s/it]  6%|▌         | 259/4650 [2:36:41<44:24:23, 36.41s/it]                                                       {'loss': 0.3222, 'learning_rate': 5e-05, 'epoch': 0.28}
  6%|▌         | 259/4650 [2:36:41<44:24:23, 36.41s/it]  6%|▌         | 260/4650 [2:37:18<44:26:01, 36.44s/it]                                                       {'loss': 0.4453, 'learning_rate': 5e-05, 'epoch': 0.28}
  6%|▌         | 260/4650 [2:37:18<44:26:01, 36.44s/it]  6%|▌         | 261/4650 [2:37:54<44:25:22, 36.44s/it]                                                       {'loss': 0.6145, 'learning_rate': 5e-05, 'epoch': 0.28}
  6%|▌         | 261/4650 [2:37:54<44:25:22, 36.44s/it]  6%|▌         | 262/4650 [2:38:30<44:23:51, 36.42s/it]                                                       {'loss': 0.4358, 'learning_rate': 5e-05, 'epoch': 0.28}
  6%|▌         | 262/4650 [2:38:30<44:23:51, 36.42s/it]  6%|▌         | 263/4650 [2:39:07<44:25:33, 36.46s/it]                                                       {'loss': 0.5731, 'learning_rate': 5e-05, 'epoch': 0.28}
  6%|▌         | 263/4650 [2:39:07<44:25:33, 36.46s/it]  6%|▌         | 264/4650 [2:39:43<44:23:35, 36.44s/it]                                                       {'loss': 0.414, 'learning_rate': 5e-05, 'epoch': 0.28}
  6%|▌         | 264/4650 [2:39:43<44:23:35, 36.44s/it]  6%|▌         | 265/4650 [2:40:20<44:25:35, 36.47s/it]                                                       {'loss': 0.3942, 'learning_rate': 5e-05, 'epoch': 0.28}
  6%|▌         | 265/4650 [2:40:20<44:25:35, 36.47s/it]  6%|▌         | 266/4650 [2:40:56<44:23:41, 36.46s/it]                                                       {'loss': 0.5557, 'learning_rate': 5e-05, 'epoch': 0.29}
  6%|▌         | 266/4650 [2:40:56<44:23:41, 36.46s/it]  6%|▌         | 267/4650 [2:41:33<44:23:43, 36.46s/it]                                                       {'loss': 0.4755, 'learning_rate': 5e-05, 'epoch': 0.29}
  6%|▌         | 267/4650 [2:41:33<44:23:43, 36.46s/it]  6%|▌         | 268/4650 [2:42:09<44:24:28, 36.48s/it]                                                       {'loss': 0.4327, 'learning_rate': 5e-05, 'epoch': 0.29}
  6%|▌         | 268/4650 [2:42:09<44:24:28, 36.48s/it]  6%|▌         | 269/4650 [2:42:46<44:24:23, 36.49s/it]                                                       {'loss': 0.4733, 'learning_rate': 5e-05, 'epoch': 0.29}
  6%|▌         | 269/4650 [2:42:46<44:24:23, 36.49s/it]  6%|▌         | 270/4650 [2:43:22<44:27:02, 36.53s/it]                                                       {'loss': 0.5896, 'learning_rate': 5e-05, 'epoch': 0.29}
  6%|▌         | 270/4650 [2:43:22<44:27:02, 36.53s/it]  6%|▌         | 271/4650 [2:43:59<44:25:11, 36.52s/it]                                                       {'loss': 0.6183, 'learning_rate': 5e-05, 'epoch': 0.29}
  6%|▌         | 271/4650 [2:43:59<44:25:11, 36.52s/it]  6%|▌         | 272/4650 [2:44:35<44:22:04, 36.48s/it]                                                       {'loss': 0.4919, 'learning_rate': 5e-05, 'epoch': 0.29}
  6%|▌         | 272/4650 [2:44:35<44:22:04, 36.48s/it]  6%|▌         | 273/4650 [2:45:12<44:22:06, 36.49s/it]                                                       {'loss': 0.3648, 'learning_rate': 5e-05, 'epoch': 0.29}
  6%|▌         | 273/4650 [2:45:12<44:22:06, 36.49s/it]  6%|▌         | 274/4650 [2:45:48<44:19:29, 36.46s/it]                                                       {'loss': 0.3766, 'learning_rate': 5e-05, 'epoch': 0.29}
  6%|▌         | 274/4650 [2:45:48<44:19:29, 36.46s/it]  6%|▌         | 275/4650 [2:46:25<44:15:56, 36.42s/it]                                                       {'loss': 0.5608, 'learning_rate': 5e-05, 'epoch': 0.3}
  6%|▌         | 275/4650 [2:46:25<44:15:56, 36.42s/it]  6%|▌         | 276/4650 [2:47:01<44:14:16, 36.41s/it]                                                       {'loss': 0.5423, 'learning_rate': 5e-05, 'epoch': 0.3}
  6%|▌         | 276/4650 [2:47:01<44:14:16, 36.41s/it]  6%|▌         | 277/4650 [2:47:37<44:10:59, 36.37s/it]                                                       {'loss': 0.3785, 'learning_rate': 5e-05, 'epoch': 0.3}
  6%|▌         | 277/4650 [2:47:37<44:10:59, 36.37s/it]  6%|▌         | 278/4650 [2:48:14<44:08:27, 36.35s/it]                                                       {'loss': 0.3769, 'learning_rate': 5e-05, 'epoch': 0.3}
  6%|▌         | 278/4650 [2:48:14<44:08:27, 36.35s/it]  6%|▌         | 279/4650 [2:48:50<44:07:12, 36.34s/it]                                                       {'loss': 0.4279, 'learning_rate': 5e-05, 'epoch': 0.3}
  6%|▌         | 279/4650 [2:48:50<44:07:12, 36.34s/it]  6%|▌         | 280/4650 [2:49:26<44:07:14, 36.35s/it]                                                       {'loss': 0.8286, 'learning_rate': 5e-05, 'epoch': 0.3}
  6%|▌         | 280/4650 [2:49:26<44:07:14, 36.35s/it]  6%|▌         | 281/4650 [2:50:03<44:05:12, 36.33s/it]                                                       {'loss': 0.4408, 'learning_rate': 5e-05, 'epoch': 0.3}
  6%|▌         | 281/4650 [2:50:03<44:05:12, 36.33s/it]  6%|▌         | 282/4650 [2:50:39<44:12:11, 36.43s/it]                                                       {'loss': 0.4907, 'learning_rate': 5e-05, 'epoch': 0.3}
  6%|▌         | 282/4650 [2:50:39<44:12:11, 36.43s/it]  6%|▌         | 283/4650 [2:51:16<44:08:59, 36.40s/it]                                                       {'loss': 0.338, 'learning_rate': 5e-05, 'epoch': 0.3}
  6%|▌         | 283/4650 [2:51:16<44:08:59, 36.40s/it]  6%|▌         | 284/4650 [2:51:52<44:07:40, 36.39s/it]                                                       {'loss': 0.3376, 'learning_rate': 5e-05, 'epoch': 0.31}
  6%|▌         | 284/4650 [2:51:52<44:07:40, 36.39s/it]  6%|▌         | 285/4650 [2:52:28<44:05:49, 36.37s/it]                                                       {'loss': 0.4546, 'learning_rate': 5e-05, 'epoch': 0.31}
  6%|▌         | 285/4650 [2:52:28<44:05:49, 36.37s/it]  6%|▌         | 286/4650 [2:53:05<44:04:10, 36.35s/it]                                                       {'loss': 0.4755, 'learning_rate': 5e-05, 'epoch': 0.31}
  6%|▌         | 286/4650 [2:53:05<44:04:10, 36.35s/it]  6%|▌         | 287/4650 [2:53:41<44:02:13, 36.34s/it]                                                       {'loss': 0.5207, 'learning_rate': 5e-05, 'epoch': 0.31}
  6%|▌         | 287/4650 [2:53:41<44:02:13, 36.34s/it]  6%|▌         | 288/4650 [2:54:17<44:01:55, 36.34s/it]                                                       {'loss': 0.4933, 'learning_rate': 5e-05, 'epoch': 0.31}
  6%|▌         | 288/4650 [2:54:17<44:01:55, 36.34s/it]  6%|▌         | 289/4650 [2:54:53<43:58:35, 36.30s/it]                                                       {'loss': 0.4727, 'learning_rate': 5e-05, 'epoch': 0.31}
  6%|▌         | 289/4650 [2:54:53<43:58:35, 36.30s/it]  6%|▌         | 290/4650 [2:55:30<43:57:37, 36.30s/it]                                                       {'loss': 0.4981, 'learning_rate': 5e-05, 'epoch': 0.31}
  6%|▌         | 290/4650 [2:55:30<43:57:37, 36.30s/it]  6%|▋         | 291/4650 [2:56:06<43:56:27, 36.29s/it]                                                       {'loss': 0.328, 'learning_rate': 5e-05, 'epoch': 0.31}
  6%|▋         | 291/4650 [2:56:06<43:56:27, 36.29s/it]  6%|▋         | 292/4650 [2:56:42<43:55:05, 36.28s/it]                                                       {'loss': 0.5155, 'learning_rate': 5e-05, 'epoch': 0.31}
  6%|▋         | 292/4650 [2:56:42<43:55:05, 36.28s/it]  6%|▋         | 293/4650 [2:57:18<43:53:52, 36.27s/it]                                                       {'loss': 0.5143, 'learning_rate': 5e-05, 'epoch': 0.31}
  6%|▋         | 293/4650 [2:57:18<43:53:52, 36.27s/it]  6%|▋         | 294/4650 [2:57:55<43:53:07, 36.27s/it]                                                       {'loss': 0.3998, 'learning_rate': 5e-05, 'epoch': 0.32}
  6%|▋         | 294/4650 [2:57:55<43:53:07, 36.27s/it]  6%|▋         | 295/4650 [2:58:31<43:51:29, 36.25s/it]                                                       {'loss': 0.5223, 'learning_rate': 5e-05, 'epoch': 0.32}
  6%|▋         | 295/4650 [2:58:31<43:51:29, 36.25s/it]  6%|▋         | 296/4650 [2:59:07<43:51:42, 36.27s/it]                                                       {'loss': 0.414, 'learning_rate': 5e-05, 'epoch': 0.32}
  6%|▋         | 296/4650 [2:59:07<43:51:42, 36.27s/it]  6%|▋         | 297/4650 [2:59:43<43:49:55, 36.25s/it]                                                       {'loss': 0.428, 'learning_rate': 5e-05, 'epoch': 0.32}
  6%|▋         | 297/4650 [2:59:43<43:49:55, 36.25s/it]  6%|▋         | 298/4650 [3:00:20<43:48:56, 36.24s/it]                                                       {'loss': 0.3632, 'learning_rate': 5e-05, 'epoch': 0.32}
  6%|▋         | 298/4650 [3:00:20<43:48:56, 36.24s/it]  6%|▋         | 299/4650 [3:00:56<43:49:17, 36.26s/it]                                                       {'loss': 0.5195, 'learning_rate': 5e-05, 'epoch': 0.32}
  6%|▋         | 299/4650 [3:00:56<43:49:17, 36.26s/it]  6%|▋         | 300/4650 [3:01:32<43:47:57, 36.25s/it]                                                       {'loss': 0.246, 'learning_rate': 5e-05, 'epoch': 0.32}
  6%|▋         | 300/4650 [3:01:32<43:47:57, 36.25s/it]  6%|▋         | 301/4650 [3:02:08<43:46:22, 36.23s/it]                                                       {'loss': 0.305, 'learning_rate': 5e-05, 'epoch': 0.32}
  6%|▋         | 301/4650 [3:02:08<43:46:22, 36.23s/it]  6%|▋         | 302/4650 [3:02:45<43:46:17, 36.24s/it]                                                       {'loss': 0.5465, 'learning_rate': 5e-05, 'epoch': 0.32}
  6%|▋         | 302/4650 [3:02:45<43:46:17, 36.24s/it]  7%|▋         | 303/4650 [3:03:21<43:45:34, 36.24s/it]                                                       {'loss': 0.5337, 'learning_rate': 5e-05, 'epoch': 0.33}
  7%|▋         | 303/4650 [3:03:21<43:45:34, 36.24s/it]  7%|▋         | 304/4650 [3:03:57<43:46:35, 36.26s/it]                                                       {'loss': 0.4436, 'learning_rate': 5e-05, 'epoch': 0.33}
  7%|▋         | 304/4650 [3:03:57<43:46:35, 36.26s/it]  7%|▋         | 305/4650 [3:04:33<43:44:51, 36.25s/it]                                                       {'loss': 0.4386, 'learning_rate': 5e-05, 'epoch': 0.33}
  7%|▋         | 305/4650 [3:04:33<43:44:51, 36.25s/it]  7%|▋         | 306/4650 [3:05:10<43:43:03, 36.23s/it]                                                       {'loss': 0.6027, 'learning_rate': 5e-05, 'epoch': 0.33}
  7%|▋         | 306/4650 [3:05:10<43:43:03, 36.23s/it]  7%|▋         | 307/4650 [3:05:46<43:42:13, 36.23s/it]                                                       {'loss': 0.4739, 'learning_rate': 5e-05, 'epoch': 0.33}
  7%|▋         | 307/4650 [3:05:46<43:42:13, 36.23s/it]  7%|▋         | 308/4650 [3:06:22<43:41:52, 36.23s/it]                                                       {'loss': 0.3866, 'learning_rate': 5e-05, 'epoch': 0.33}
  7%|▋         | 308/4650 [3:06:22<43:41:52, 36.23s/it]  7%|▋         | 309/4650 [3:06:58<43:41:12, 36.23s/it]                                                       {'loss': 0.4756, 'learning_rate': 5e-05, 'epoch': 0.33}
  7%|▋         | 309/4650 [3:06:58<43:41:12, 36.23s/it]  7%|▋         | 310/4650 [3:07:35<43:41:01, 36.24s/it]                                                       {'loss': 0.6909, 'learning_rate': 5e-05, 'epoch': 0.33}
  7%|▋         | 310/4650 [3:07:35<43:41:01, 36.24s/it]  7%|▋         | 311/4650 [3:08:11<43:40:07, 36.23s/it]                                                       {'loss': 0.5254, 'learning_rate': 5e-05, 'epoch': 0.33}
  7%|▋         | 311/4650 [3:08:11<43:40:07, 36.23s/it]  7%|▋         | 312/4650 [3:08:47<43:39:56, 36.24s/it]                                                       {'loss': 0.3861, 'learning_rate': 5e-05, 'epoch': 0.34}
  7%|▋         | 312/4650 [3:08:47<43:39:56, 36.24s/it]  7%|▋         | 313/4650 [3:09:23<43:36:56, 36.20s/it]                                                       {'loss': 0.4094, 'learning_rate': 5e-05, 'epoch': 0.34}
  7%|▋         | 313/4650 [3:09:23<43:36:56, 36.20s/it]  7%|▋         | 314/4650 [3:09:59<43:36:49, 36.21s/it]                                                       {'loss': 0.5108, 'learning_rate': 5e-05, 'epoch': 0.34}
  7%|▋         | 314/4650 [3:09:59<43:36:49, 36.21s/it]  7%|▋         | 315/4650 [3:10:36<43:35:07, 36.20s/it]                                                       {'loss': 0.3028, 'learning_rate': 5e-05, 'epoch': 0.34}
  7%|▋         | 315/4650 [3:10:36<43:35:07, 36.20s/it]  7%|▋         | 316/4650 [3:11:12<43:36:53, 36.23s/it]                                                       {'loss': 0.3191, 'learning_rate': 5e-05, 'epoch': 0.34}
  7%|▋         | 316/4650 [3:11:12<43:36:53, 36.23s/it]  7%|▋         | 317/4650 [3:11:48<43:35:00, 36.21s/it]                                                       {'loss': 0.3071, 'learning_rate': 5e-05, 'epoch': 0.34}
  7%|▋         | 317/4650 [3:11:48<43:35:00, 36.21s/it]  7%|▋         | 318/4650 [3:12:24<43:32:41, 36.19s/it]                                                       {'loss': 0.3929, 'learning_rate': 5e-05, 'epoch': 0.34}
  7%|▋         | 318/4650 [3:12:24<43:32:41, 36.19s/it]  7%|▋         | 319/4650 [3:13:00<43:32:18, 36.19s/it]                                                       {'loss': 0.4348, 'learning_rate': 5e-05, 'epoch': 0.34}
  7%|▋         | 319/4650 [3:13:00<43:32:18, 36.19s/it]  7%|▋         | 320/4650 [3:13:37<43:33:17, 36.21s/it]                                                       {'loss': 0.4122, 'learning_rate': 5e-05, 'epoch': 0.34}
  7%|▋         | 320/4650 [3:13:37<43:33:17, 36.21s/it]  7%|▋         | 321/4650 [3:14:13<43:31:54, 36.20s/it]                                                       {'loss': 0.4528, 'learning_rate': 5e-05, 'epoch': 0.34}
  7%|▋         | 321/4650 [3:14:13<43:31:54, 36.20s/it]  7%|▋         | 322/4650 [3:14:49<43:30:23, 36.19s/it]                                                       {'loss': 0.5123, 'learning_rate': 5e-05, 'epoch': 0.35}
  7%|▋         | 322/4650 [3:14:49<43:30:23, 36.19s/it]  7%|▋         | 323/4650 [3:15:25<43:28:48, 36.17s/it]                                                       {'loss': 0.4061, 'learning_rate': 5e-05, 'epoch': 0.35}
  7%|▋         | 323/4650 [3:15:25<43:28:48, 36.17s/it]  7%|▋         | 324/4650 [3:16:01<43:27:46, 36.17s/it]                                                       {'loss': 0.3567, 'learning_rate': 5e-05, 'epoch': 0.35}
  7%|▋         | 324/4650 [3:16:01<43:27:46, 36.17s/it]  7%|▋         | 325/4650 [3:16:37<43:27:05, 36.17s/it]                                                       {'loss': 0.5225, 'learning_rate': 5e-05, 'epoch': 0.35}
  7%|▋         | 325/4650 [3:16:37<43:27:05, 36.17s/it]  7%|▋         | 326/4650 [3:17:14<43:26:29, 36.17s/it]                                                       {'loss': 0.5312, 'learning_rate': 5e-05, 'epoch': 0.35}
  7%|▋         | 326/4650 [3:17:14<43:26:29, 36.17s/it]  7%|▋         | 327/4650 [3:17:50<43:23:35, 36.14s/it]                                                       {'loss': 0.3831, 'learning_rate': 5e-05, 'epoch': 0.35}
  7%|▋         | 327/4650 [3:17:50<43:23:35, 36.14s/it]  7%|▋         | 328/4650 [3:18:26<43:23:48, 36.15s/it]                                                       {'loss': 0.514, 'learning_rate': 5e-05, 'epoch': 0.35}
  7%|▋         | 328/4650 [3:18:26<43:23:48, 36.15s/it]  7%|▋         | 329/4650 [3:19:02<43:23:19, 36.15s/it]                                                       {'loss': 0.5264, 'learning_rate': 5e-05, 'epoch': 0.35}
  7%|▋         | 329/4650 [3:19:02<43:23:19, 36.15s/it]  7%|▋         | 330/4650 [3:19:38<43:23:26, 36.16s/it]                                                       {'loss': 0.4087, 'learning_rate': 5e-05, 'epoch': 0.35}
  7%|▋         | 330/4650 [3:19:38<43:23:26, 36.16s/it]  7%|▋         | 331/4650 [3:20:14<43:23:43, 36.17s/it]                                                       {'loss': 0.4219, 'learning_rate': 5e-05, 'epoch': 0.36}
  7%|▋         | 331/4650 [3:20:14<43:23:43, 36.17s/it]  7%|▋         | 332/4650 [3:20:50<43:22:56, 36.17s/it]                                                       {'loss': 0.5958, 'learning_rate': 5e-05, 'epoch': 0.36}
  7%|▋         | 332/4650 [3:20:51<43:22:56, 36.17s/it]  7%|▋         | 333/4650 [3:21:27<43:25:06, 36.21s/it]                                                       {'loss': 0.3256, 'learning_rate': 5e-05, 'epoch': 0.36}
  7%|▋         | 333/4650 [3:21:27<43:25:06, 36.21s/it]  7%|▋         | 334/4650 [3:22:03<43:22:38, 36.18s/it]                                                       {'loss': 0.3662, 'learning_rate': 5e-05, 'epoch': 0.36}
  7%|▋         | 334/4650 [3:22:03<43:22:38, 36.18s/it]  7%|▋         | 335/4650 [3:22:39<43:21:34, 36.17s/it]                                                       {'loss': 0.6121, 'learning_rate': 5e-05, 'epoch': 0.36}
  7%|▋         | 335/4650 [3:22:39<43:21:34, 36.17s/it]  7%|▋         | 336/4650 [3:23:15<43:21:22, 36.18s/it]                                                       {'loss': 0.4724, 'learning_rate': 5e-05, 'epoch': 0.36}
  7%|▋         | 336/4650 [3:23:15<43:21:22, 36.18s/it]  7%|▋         | 337/4650 [3:23:51<43:19:14, 36.16s/it]                                                       {'loss': 0.3726, 'learning_rate': 5e-05, 'epoch': 0.36}
  7%|▋         | 337/4650 [3:23:51<43:19:14, 36.16s/it]  7%|▋         | 338/4650 [3:24:28<43:18:27, 36.16s/it]                                                       {'loss': 0.5, 'learning_rate': 5e-05, 'epoch': 0.36}
  7%|▋         | 338/4650 [3:24:28<43:18:27, 36.16s/it]  7%|▋         | 339/4650 [3:25:04<43:15:59, 36.13s/it]                                                       {'loss': 0.4267, 'learning_rate': 5e-05, 'epoch': 0.36}
  7%|▋         | 339/4650 [3:25:04<43:15:59, 36.13s/it]  7%|▋         | 340/4650 [3:25:40<43:16:12, 36.14s/it]                                                       {'loss': 0.4953, 'learning_rate': 5e-05, 'epoch': 0.37}
  7%|▋         | 340/4650 [3:25:40<43:16:12, 36.14s/it]  7%|▋         | 341/4650 [3:26:16<43:17:14, 36.16s/it]                                                       {'loss': 0.4974, 'learning_rate': 5e-05, 'epoch': 0.37}
  7%|▋         | 341/4650 [3:26:16<43:17:14, 36.16s/it]  7%|▋         | 342/4650 [3:26:52<43:16:45, 36.17s/it]                                                       {'loss': 0.3973, 'learning_rate': 5e-05, 'epoch': 0.37}
  7%|▋         | 342/4650 [3:26:52<43:16:45, 36.17s/it]  7%|▋         | 343/4650 [3:27:28<43:15:45, 36.16s/it]                                                       {'loss': 0.429, 'learning_rate': 5e-05, 'epoch': 0.37}
  7%|▋         | 343/4650 [3:27:28<43:15:45, 36.16s/it]  7%|▋         | 344/4650 [3:28:04<43:16:01, 36.17s/it]                                                       {'loss': 0.3617, 'learning_rate': 5e-05, 'epoch': 0.37}
  7%|▋         | 344/4650 [3:28:04<43:16:01, 36.17s/it]  7%|▋         | 345/4650 [3:28:41<43:15:01, 36.17s/it]                                                       {'loss': 0.4496, 'learning_rate': 5e-05, 'epoch': 0.37}
  7%|▋         | 345/4650 [3:28:41<43:15:01, 36.17s/it]  7%|▋         | 346/4650 [3:29:17<43:14:45, 36.17s/it]                                                       {'loss': 0.4993, 'learning_rate': 5e-05, 'epoch': 0.37}
  7%|▋         | 346/4650 [3:29:17<43:14:45, 36.17s/it]  7%|▋         | 347/4650 [3:29:53<43:13:43, 36.17s/it]                                                       {'loss': 0.4269, 'learning_rate': 5e-05, 'epoch': 0.37}
  7%|▋         | 347/4650 [3:29:53<43:13:43, 36.17s/it]  7%|▋         | 348/4650 [3:30:29<43:12:25, 36.16s/it]                                                       {'loss': 0.4054, 'learning_rate': 5e-05, 'epoch': 0.37}
  7%|▋         | 348/4650 [3:30:29<43:12:25, 36.16s/it]  8%|▊         | 349/4650 [3:31:05<43:10:55, 36.14s/it]                                                       {'loss': 0.3551, 'learning_rate': 5e-05, 'epoch': 0.38}
  8%|▊         | 349/4650 [3:31:05<43:10:55, 36.14s/it]  8%|▊         | 350/4650 [3:31:41<43:10:45, 36.15s/it]                                                       {'loss': 0.3573, 'learning_rate': 5e-05, 'epoch': 0.38}
  8%|▊         | 350/4650 [3:31:41<43:10:45, 36.15s/it]  8%|▊         | 351/4650 [3:32:18<43:10:13, 36.15s/it]                                                       {'loss': 0.3377, 'learning_rate': 5e-05, 'epoch': 0.38}
  8%|▊         | 351/4650 [3:32:18<43:10:13, 36.15s/it]  8%|▊         | 352/4650 [3:32:54<43:09:19, 36.15s/it]                                                       {'loss': 0.5885, 'learning_rate': 5e-05, 'epoch': 0.38}
  8%|▊         | 352/4650 [3:32:54<43:09:19, 36.15s/it]  8%|▊         | 353/4650 [3:33:30<43:08:12, 36.14s/it]                                                       {'loss': 0.3794, 'learning_rate': 5e-05, 'epoch': 0.38}
  8%|▊         | 353/4650 [3:33:30<43:08:12, 36.14s/it]  8%|▊         | 354/4650 [3:34:06<43:07:28, 36.14s/it]                                                       {'loss': 0.6688, 'learning_rate': 5e-05, 'epoch': 0.38}
  8%|▊         | 354/4650 [3:34:06<43:07:28, 36.14s/it]  8%|▊         | 355/4650 [3:34:42<43:06:53, 36.14s/it]                                                       {'loss': 0.4861, 'learning_rate': 5e-05, 'epoch': 0.38}
  8%|▊         | 355/4650 [3:34:42<43:06:53, 36.14s/it]  8%|▊         | 356/4650 [3:35:18<43:07:34, 36.16s/it]                                                       {'loss': 0.3775, 'learning_rate': 5e-05, 'epoch': 0.38}
  8%|▊         | 356/4650 [3:35:18<43:07:34, 36.16s/it]  8%|▊         | 357/4650 [3:35:55<43:08:31, 36.18s/it]                                                       {'loss': 0.4671, 'learning_rate': 5e-05, 'epoch': 0.38}
  8%|▊         | 357/4650 [3:35:55<43:08:31, 36.18s/it]  8%|▊         | 358/4650 [3:36:31<43:07:58, 36.18s/it]                                                       {'loss': 0.5803, 'learning_rate': 5e-05, 'epoch': 0.38}
  8%|▊         | 358/4650 [3:36:31<43:07:58, 36.18s/it]  8%|▊         | 359/4650 [3:37:07<43:05:41, 36.16s/it]                                                       {'loss': 0.2945, 'learning_rate': 5e-05, 'epoch': 0.39}
  8%|▊         | 359/4650 [3:37:07<43:05:41, 36.16s/it]  8%|▊         | 360/4650 [3:37:43<43:04:26, 36.15s/it]                                                       {'loss': 0.44, 'learning_rate': 5e-05, 'epoch': 0.39}
  8%|▊         | 360/4650 [3:37:43<43:04:26, 36.15s/it]  8%|▊         | 361/4650 [3:38:19<43:02:14, 36.12s/it]                                                       {'loss': 0.4999, 'learning_rate': 5e-05, 'epoch': 0.39}
  8%|▊         | 361/4650 [3:38:19<43:02:14, 36.12s/it]  8%|▊         | 362/4650 [3:38:55<43:01:17, 36.12s/it]                                                       {'loss': 0.3416, 'learning_rate': 5e-05, 'epoch': 0.39}
  8%|▊         | 362/4650 [3:38:55<43:01:17, 36.12s/it]  8%|▊         | 363/4650 [3:39:31<42:59:44, 36.11s/it]                                                       {'loss': 0.5501, 'learning_rate': 5e-05, 'epoch': 0.39}
  8%|▊         | 363/4650 [3:39:31<42:59:44, 36.11s/it]  8%|▊         | 364/4650 [3:40:07<43:00:09, 36.12s/it]                                                       {'loss': 0.3917, 'learning_rate': 5e-05, 'epoch': 0.39}
  8%|▊         | 364/4650 [3:40:07<43:00:09, 36.12s/it]  8%|▊         | 365/4650 [3:40:43<42:59:34, 36.12s/it]                                                       {'loss': 0.5693, 'learning_rate': 5e-05, 'epoch': 0.39}
  8%|▊         | 365/4650 [3:40:43<42:59:34, 36.12s/it]  8%|▊         | 366/4650 [3:41:20<42:59:43, 36.13s/it]                                                       {'loss': 0.3382, 'learning_rate': 5e-05, 'epoch': 0.39}
  8%|▊         | 366/4650 [3:41:20<42:59:43, 36.13s/it]  8%|▊         | 367/4650 [3:41:56<43:01:05, 36.16s/it]                                                       {'loss': 0.3627, 'learning_rate': 5e-05, 'epoch': 0.39}
  8%|▊         | 367/4650 [3:41:56<43:01:05, 36.16s/it]  8%|▊         | 368/4650 [3:42:32<42:59:49, 36.15s/it]                                                       {'loss': 0.3912, 'learning_rate': 5e-05, 'epoch': 0.4}
  8%|▊         | 368/4650 [3:42:32<42:59:49, 36.15s/it]  8%|▊         | 369/4650 [3:43:08<42:58:15, 36.14s/it]                                                       {'loss': 0.2663, 'learning_rate': 5e-05, 'epoch': 0.4}
  8%|▊         | 369/4650 [3:43:08<42:58:15, 36.14s/it]  8%|▊         | 370/4650 [3:43:44<42:58:09, 36.14s/it]                                                       {'loss': 0.4108, 'learning_rate': 5e-05, 'epoch': 0.4}
  8%|▊         | 370/4650 [3:43:44<42:58:09, 36.14s/it]  8%|▊         | 371/4650 [3:44:20<42:57:04, 36.14s/it]                                                       {'loss': 0.4493, 'learning_rate': 5e-05, 'epoch': 0.4}
  8%|▊         | 371/4650 [3:44:20<42:57:04, 36.14s/it]  8%|▊         | 372/4650 [3:44:57<42:57:50, 36.15s/it]                                                       {'loss': 0.5651, 'learning_rate': 5e-05, 'epoch': 0.4}
  8%|▊         | 372/4650 [3:44:57<42:57:50, 36.15s/it]  8%|▊         | 373/4650 [3:45:33<42:57:23, 36.16s/it]                                                       {'loss': 0.4121, 'learning_rate': 5e-05, 'epoch': 0.4}
  8%|▊         | 373/4650 [3:45:33<42:57:23, 36.16s/it]  8%|▊         | 374/4650 [3:46:09<42:59:12, 36.19s/it]                                                       {'loss': 0.3029, 'learning_rate': 5e-05, 'epoch': 0.4}
  8%|▊         | 374/4650 [3:46:09<42:59:12, 36.19s/it]  8%|▊         | 375/4650 [3:46:45<42:59:13, 36.20s/it]                                                       {'loss': 0.3348, 'learning_rate': 5e-05, 'epoch': 0.4}
  8%|▊         | 375/4650 [3:46:45<42:59:13, 36.20s/it]  8%|▊         | 376/4650 [3:47:21<43:00:07, 36.22s/it]                                                       {'loss': 0.5169, 'learning_rate': 5e-05, 'epoch': 0.4}
  8%|▊         | 376/4650 [3:47:21<43:00:07, 36.22s/it]  8%|▊         | 377/4650 [3:47:58<43:02:02, 36.26s/it]                                                       {'loss': 0.4246, 'learning_rate': 5e-05, 'epoch': 0.41}
  8%|▊         | 377/4650 [3:47:58<43:02:02, 36.26s/it]  8%|▊         | 378/4650 [3:48:34<43:03:00, 36.28s/it]                                                       {'loss': 0.2802, 'learning_rate': 5e-05, 'epoch': 0.41}
  8%|▊         | 378/4650 [3:48:34<43:03:00, 36.28s/it]  8%|▊         | 379/4650 [3:49:10<43:02:39, 36.28s/it]                                                       {'loss': 0.5103, 'learning_rate': 5e-05, 'epoch': 0.41}
  8%|▊         | 379/4650 [3:49:10<43:02:39, 36.28s/it]  8%|▊         | 380/4650 [3:49:47<43:02:44, 36.29s/it]                                                       {'loss': 0.389, 'learning_rate': 5e-05, 'epoch': 0.41}
  8%|▊         | 380/4650 [3:49:47<43:02:44, 36.29s/it]  8%|▊         | 381/4650 [3:50:23<43:02:28, 36.30s/it]                                                       {'loss': 0.3717, 'learning_rate': 5e-05, 'epoch': 0.41}
  8%|▊         | 381/4650 [3:50:23<43:02:28, 36.30s/it]  8%|▊         | 382/4650 [3:50:59<42:59:54, 36.27s/it]                                                       {'loss': 0.3684, 'learning_rate': 5e-05, 'epoch': 0.41}
  8%|▊         | 382/4650 [3:50:59<42:59:54, 36.27s/it]  8%|▊         | 383/4650 [3:51:35<42:58:49, 36.26s/it]                                                       {'loss': 0.4559, 'learning_rate': 5e-05, 'epoch': 0.41}
  8%|▊         | 383/4650 [3:51:36<42:58:49, 36.26s/it]  8%|▊         | 384/4650 [3:52:12<43:01:39, 36.31s/it]                                                       {'loss': 0.6076, 'learning_rate': 5e-05, 'epoch': 0.41}
  8%|▊         | 384/4650 [3:52:12<43:01:39, 36.31s/it]  8%|▊         | 385/4650 [3:52:48<43:00:28, 36.30s/it]                                                       {'loss': 0.4016, 'learning_rate': 5e-05, 'epoch': 0.41}
  8%|▊         | 385/4650 [3:52:48<43:00:28, 36.30s/it]  8%|▊         | 386/4650 [3:53:25<43:00:50, 36.32s/it]                                                       {'loss': 0.384, 'learning_rate': 5e-05, 'epoch': 0.41}
  8%|▊         | 386/4650 [3:53:25<43:00:50, 36.32s/it]  8%|▊         | 387/4650 [3:54:01<43:01:35, 36.33s/it]                                                       {'loss': 0.3042, 'learning_rate': 5e-05, 'epoch': 0.42}
  8%|▊         | 387/4650 [3:54:01<43:01:35, 36.33s/it]  8%|▊         | 388/4650 [3:54:37<43:02:37, 36.36s/it]                                                       {'loss': 0.4388, 'learning_rate': 5e-05, 'epoch': 0.42}
  8%|▊         | 388/4650 [3:54:37<43:02:37, 36.36s/it]  8%|▊         | 389/4650 [3:55:14<43:00:49, 36.34s/it]                                                       {'loss': 0.3892, 'learning_rate': 5e-05, 'epoch': 0.42}
  8%|▊         | 389/4650 [3:55:14<43:00:49, 36.34s/it]  8%|▊         | 390/4650 [3:55:50<42:59:52, 36.34s/it]                                                       {'loss': 0.2788, 'learning_rate': 5e-05, 'epoch': 0.42}
  8%|▊         | 390/4650 [3:55:50<42:59:52, 36.34s/it]  8%|▊         | 391/4650 [3:56:26<42:59:49, 36.34s/it]                                                       {'loss': 0.5148, 'learning_rate': 5e-05, 'epoch': 0.42}
  8%|▊         | 391/4650 [3:56:26<42:59:49, 36.34s/it]  8%|▊         | 392/4650 [3:57:03<43:00:27, 36.36s/it]                                                       {'loss': 0.3915, 'learning_rate': 5e-05, 'epoch': 0.42}
  8%|▊         | 392/4650 [3:57:03<43:00:27, 36.36s/it]  8%|▊         | 393/4650 [3:57:39<43:00:48, 36.37s/it]                                                       {'loss': 0.4194, 'learning_rate': 5e-05, 'epoch': 0.42}
  8%|▊         | 393/4650 [3:57:39<43:00:48, 36.37s/it]  8%|▊         | 394/4650 [3:58:15<42:58:57, 36.36s/it]                                                       {'loss': 0.3732, 'learning_rate': 5e-05, 'epoch': 0.42}
  8%|▊         | 394/4650 [3:58:15<42:58:57, 36.36s/it]  8%|▊         | 395/4650 [3:58:52<42:59:57, 36.38s/it]                                                       {'loss': 0.6059, 'learning_rate': 5e-05, 'epoch': 0.42}
  8%|▊         | 395/4650 [3:58:52<42:59:57, 36.38s/it]  9%|▊         | 396/4650 [3:59:28<42:59:05, 36.38s/it]                                                       {'loss': 0.4187, 'learning_rate': 5e-05, 'epoch': 0.43}
  9%|▊         | 396/4650 [3:59:28<42:59:05, 36.38s/it]  9%|▊         | 397/4650 [4:00:05<42:59:20, 36.39s/it]                                                       {'loss': 0.4105, 'learning_rate': 5e-05, 'epoch': 0.43}
  9%|▊         | 397/4650 [4:00:05<42:59:20, 36.39s/it]  9%|▊         | 398/4650 [4:00:41<42:58:30, 36.39s/it]                                                       {'loss': 0.4529, 'learning_rate': 5e-05, 'epoch': 0.43}
  9%|▊         | 398/4650 [4:00:41<42:58:30, 36.39s/it]  9%|▊         | 399/4650 [4:01:17<42:58:56, 36.40s/it]                                                       {'loss': 0.692, 'learning_rate': 5e-05, 'epoch': 0.43}
  9%|▊         | 399/4650 [4:01:17<42:58:56, 36.40s/it]  9%|▊         | 400/4650 [4:01:54<42:59:00, 36.41s/it]                                                       {'loss': 0.3374, 'learning_rate': 5e-05, 'epoch': 0.43}
  9%|▊         | 400/4650 [4:01:54<42:59:00, 36.41s/it]  9%|▊         | 401/4650 [4:02:30<42:57:38, 36.40s/it]                                                       {'loss': 0.4171, 'learning_rate': 5e-05, 'epoch': 0.43}
  9%|▊         | 401/4650 [4:02:30<42:57:38, 36.40s/it]  9%|▊         | 402/4650 [4:03:07<42:58:40, 36.42s/it]                                                       {'loss': 0.3231, 'learning_rate': 5e-05, 'epoch': 0.43}
  9%|▊         | 402/4650 [4:03:07<42:58:40, 36.42s/it]  9%|▊         | 403/4650 [4:03:43<42:56:50, 36.40s/it]                                                       {'loss': 0.491, 'learning_rate': 5e-05, 'epoch': 0.43}
  9%|▊         | 403/4650 [4:03:43<42:56:50, 36.40s/it]  9%|▊         | 404/4650 [4:04:20<42:59:44, 36.45s/it]                                                       {'loss': 0.3295, 'learning_rate': 5e-05, 'epoch': 0.43}
  9%|▊         | 404/4650 [4:04:20<42:59:44, 36.45s/it]  9%|▊         | 405/4650 [4:04:56<42:56:44, 36.42s/it]                                                       {'loss': 0.4398, 'learning_rate': 5e-05, 'epoch': 0.44}
  9%|▊         | 405/4650 [4:04:56<42:56:44, 36.42s/it]  9%|▊         | 406/4650 [4:05:33<42:58:46, 36.46s/it]                                                       {'loss': 0.4555, 'learning_rate': 5e-05, 'epoch': 0.44}
  9%|▊         | 406/4650 [4:05:33<42:58:46, 36.46s/it]  9%|▉         | 407/4650 [4:06:09<42:57:05, 36.44s/it]                                                       {'loss': 0.5428, 'learning_rate': 5e-05, 'epoch': 0.44}
  9%|▉         | 407/4650 [4:06:09<42:57:05, 36.44s/it]  9%|▉         | 408/4650 [4:06:45<42:57:37, 36.46s/it]                                                       {'loss': 0.5349, 'learning_rate': 5e-05, 'epoch': 0.44}
  9%|▉         | 408/4650 [4:06:45<42:57:37, 36.46s/it]  9%|▉         | 409/4650 [4:07:22<42:57:20, 36.46s/it]                                                       {'loss': 0.3592, 'learning_rate': 5e-05, 'epoch': 0.44}
  9%|▉         | 409/4650 [4:07:22<42:57:20, 36.46s/it]  9%|▉         | 410/4650 [4:07:59<42:58:49, 36.49s/it]                                                       {'loss': 0.5908, 'learning_rate': 5e-05, 'epoch': 0.44}
  9%|▉         | 410/4650 [4:07:59<42:58:49, 36.49s/it]  9%|▉         | 411/4650 [4:08:35<42:56:33, 36.47s/it]                                                       {'loss': 0.3638, 'learning_rate': 5e-05, 'epoch': 0.44}
  9%|▉         | 411/4650 [4:08:35<42:56:33, 36.47s/it]  9%|▉         | 412/4650 [4:09:11<42:56:07, 36.47s/it]                                                       {'loss': 0.3152, 'learning_rate': 5e-05, 'epoch': 0.44}
  9%|▉         | 412/4650 [4:09:11<42:56:07, 36.47s/it]  9%|▉         | 413/4650 [4:09:48<42:55:26, 36.47s/it]                                                       {'loss': 0.4482, 'learning_rate': 5e-05, 'epoch': 0.44}
  9%|▉         | 413/4650 [4:09:48<42:55:26, 36.47s/it]  9%|▉         | 414/4650 [4:10:24<42:53:52, 36.46s/it]                                                       {'loss': 0.5127, 'learning_rate': 5e-05, 'epoch': 0.44}
  9%|▉         | 414/4650 [4:10:24<42:53:52, 36.46s/it]  9%|▉         | 415/4650 [4:11:01<42:53:10, 36.46s/it]                                                       {'loss': 0.5858, 'learning_rate': 5e-05, 'epoch': 0.45}
  9%|▉         | 415/4650 [4:11:01<42:53:10, 36.46s/it]  9%|▉         | 416/4650 [4:11:37<42:51:38, 36.44s/it]                                                       {'loss': 0.2742, 'learning_rate': 5e-05, 'epoch': 0.45}
  9%|▉         | 416/4650 [4:11:37<42:51:38, 36.44s/it]  9%|▉         | 417/4650 [4:12:14<42:51:03, 36.44s/it]                                                       {'loss': 0.5005, 'learning_rate': 5e-05, 'epoch': 0.45}
  9%|▉         | 417/4650 [4:12:14<42:51:03, 36.44s/it]  9%|▉         | 418/4650 [4:12:50<42:54:28, 36.50s/it]                                                       {'loss': 0.38, 'learning_rate': 5e-05, 'epoch': 0.45}
  9%|▉         | 418/4650 [4:12:50<42:54:28, 36.50s/it]  9%|▉         | 419/4650 [4:13:27<42:53:10, 36.49s/it]                                                       {'loss': 0.3005, 'learning_rate': 5e-05, 'epoch': 0.45}
  9%|▉         | 419/4650 [4:13:27<42:53:10, 36.49s/it]  9%|▉         | 420/4650 [4:14:03<42:52:28, 36.49s/it]                                                       {'loss': 0.318, 'learning_rate': 5e-05, 'epoch': 0.45}
  9%|▉         | 420/4650 [4:14:03<42:52:28, 36.49s/it]  9%|▉         | 421/4650 [4:14:40<42:50:57, 36.48s/it]                                                       {'loss': 0.1545, 'learning_rate': 5e-05, 'epoch': 0.45}
  9%|▉         | 421/4650 [4:14:40<42:50:57, 36.48s/it]  9%|▉         | 422/4650 [4:15:16<42:50:13, 36.47s/it]                                                       {'loss': 0.277, 'learning_rate': 5e-05, 'epoch': 0.45}
  9%|▉         | 422/4650 [4:15:16<42:50:13, 36.47s/it]  9%|▉         | 423/4650 [4:15:52<42:47:49, 36.45s/it]                                                       {'loss': 0.3233, 'learning_rate': 5e-05, 'epoch': 0.45}
  9%|▉         | 423/4650 [4:15:52<42:47:49, 36.45s/it]  9%|▉         | 424/4650 [4:16:29<42:47:58, 36.46s/it]                                                       {'loss': 0.6719, 'learning_rate': 5e-05, 'epoch': 0.46}
  9%|▉         | 424/4650 [4:16:29<42:47:58, 36.46s/it]  9%|▉         | 425/4650 [4:17:05<42:47:46, 36.47s/it]                                                       {'loss': 0.5067, 'learning_rate': 5e-05, 'epoch': 0.46}
  9%|▉         | 425/4650 [4:17:05<42:47:46, 36.47s/it]  9%|▉         | 426/4650 [4:17:42<42:46:01, 36.45s/it]                                                       {'loss': 0.2828, 'learning_rate': 5e-05, 'epoch': 0.46}
  9%|▉         | 426/4650 [4:17:42<42:46:01, 36.45s/it]  9%|▉         | 427/4650 [4:18:18<42:46:49, 36.47s/it]                                                       {'loss': 0.5148, 'learning_rate': 5e-05, 'epoch': 0.46}
  9%|▉         | 427/4650 [4:18:18<42:46:49, 36.47s/it]  9%|▉         | 428/4650 [4:18:55<42:45:19, 36.46s/it]                                                       {'loss': 0.4412, 'learning_rate': 5e-05, 'epoch': 0.46}
  9%|▉         | 428/4650 [4:18:55<42:45:19, 36.46s/it]  9%|▉         | 429/4650 [4:19:31<42:44:17, 36.45s/it]                                                       {'loss': 0.3264, 'learning_rate': 5e-05, 'epoch': 0.46}
  9%|▉         | 429/4650 [4:19:31<42:44:17, 36.45s/it]  9%|▉         | 430/4650 [4:20:08<42:42:41, 36.44s/it]                                                       {'loss': 0.3498, 'learning_rate': 5e-05, 'epoch': 0.46}
  9%|▉         | 430/4650 [4:20:08<42:42:41, 36.44s/it]  9%|▉         | 431/4650 [4:20:44<42:41:40, 36.43s/it]                                                       {'loss': 0.5402, 'learning_rate': 5e-05, 'epoch': 0.46}
  9%|▉         | 431/4650 [4:20:44<42:41:40, 36.43s/it]  9%|▉         | 432/4650 [4:21:20<42:39:49, 36.41s/it]                                                       {'loss': 0.402, 'learning_rate': 5e-05, 'epoch': 0.46}
  9%|▉         | 432/4650 [4:21:20<42:39:49, 36.41s/it]  9%|▉         | 433/4650 [4:21:57<42:37:50, 36.39s/it]                                                       {'loss': 0.3547, 'learning_rate': 5e-05, 'epoch': 0.47}
  9%|▉         | 433/4650 [4:21:57<42:37:50, 36.39s/it]  9%|▉         | 434/4650 [4:22:33<42:35:46, 36.37s/it]                                                       {'loss': 0.4412, 'learning_rate': 5e-05, 'epoch': 0.47}
  9%|▉         | 434/4650 [4:22:33<42:35:46, 36.37s/it]  9%|▉         | 435/4650 [4:23:10<42:37:18, 36.40s/it]                                                       {'loss': 0.4033, 'learning_rate': 5e-05, 'epoch': 0.47}
  9%|▉         | 435/4650 [4:23:10<42:37:18, 36.40s/it]  9%|▉         | 436/4650 [4:23:46<42:35:53, 36.39s/it]                                                       {'loss': 0.5195, 'learning_rate': 5e-05, 'epoch': 0.47}
  9%|▉         | 436/4650 [4:23:46<42:35:53, 36.39s/it]  9%|▉         | 437/4650 [4:24:22<42:33:08, 36.36s/it]                                                       {'loss': 0.3685, 'learning_rate': 5e-05, 'epoch': 0.47}
  9%|▉         | 437/4650 [4:24:22<42:33:08, 36.36s/it]  9%|▉         | 438/4650 [4:24:59<42:33:21, 36.37s/it]                                                       {'loss': 0.6345, 'learning_rate': 5e-05, 'epoch': 0.47}
  9%|▉         | 438/4650 [4:24:59<42:33:21, 36.37s/it]  9%|▉         | 439/4650 [4:25:35<42:30:58, 36.35s/it]                                                       {'loss': 0.4409, 'learning_rate': 5e-05, 'epoch': 0.47}
  9%|▉         | 439/4650 [4:25:35<42:30:58, 36.35s/it]  9%|▉         | 440/4650 [4:26:11<42:29:14, 36.33s/it]                                                       {'loss': 0.2782, 'learning_rate': 5e-05, 'epoch': 0.47}
  9%|▉         | 440/4650 [4:26:11<42:29:14, 36.33s/it]  9%|▉         | 441/4650 [4:26:47<42:27:17, 36.31s/it]                                                       {'loss': 0.4682, 'learning_rate': 5e-05, 'epoch': 0.47}
  9%|▉         | 441/4650 [4:26:47<42:27:17, 36.31s/it] 10%|▉         | 442/4650 [4:27:24<42:25:25, 36.29s/it]                                                       {'loss': 0.3092, 'learning_rate': 5e-05, 'epoch': 0.48}
 10%|▉         | 442/4650 [4:27:24<42:25:25, 36.29s/it] 10%|▉         | 443/4650 [4:28:00<42:29:15, 36.36s/it]                                                       {'loss': 0.4475, 'learning_rate': 5e-05, 'epoch': 0.48}
 10%|▉         | 443/4650 [4:28:00<42:29:15, 36.36s/it] 10%|▉         | 444/4650 [4:28:37<42:27:58, 36.35s/it]                                                       {'loss': 0.4598, 'learning_rate': 5e-05, 'epoch': 0.48}
 10%|▉         | 444/4650 [4:28:37<42:27:58, 36.35s/it] 10%|▉         | 445/4650 [4:29:13<42:27:10, 36.34s/it]                                                       {'loss': 0.4053, 'learning_rate': 5e-05, 'epoch': 0.48}
 10%|▉         | 445/4650 [4:29:13<42:27:10, 36.34s/it] 10%|▉         | 446/4650 [4:29:49<42:26:01, 36.34s/it]                                                       {'loss': 0.4244, 'learning_rate': 5e-05, 'epoch': 0.48}
 10%|▉         | 446/4650 [4:29:49<42:26:01, 36.34s/it] 10%|▉         | 447/4650 [4:30:26<42:24:16, 36.32s/it]                                                       {'loss': 0.2488, 'learning_rate': 5e-05, 'epoch': 0.48}
 10%|▉         | 447/4650 [4:30:26<42:24:16, 36.32s/it] 10%|▉         | 448/4650 [4:31:02<42:23:42, 36.32s/it]                                                       {'loss': 0.3301, 'learning_rate': 5e-05, 'epoch': 0.48}
 10%|▉         | 448/4650 [4:31:02<42:23:42, 36.32s/it] 10%|▉         | 449/4650 [4:31:38<42:22:16, 36.31s/it]                                                       {'loss': 0.493, 'learning_rate': 5e-05, 'epoch': 0.48}
 10%|▉         | 449/4650 [4:31:38<42:22:16, 36.31s/it] 10%|▉         | 450/4650 [4:32:14<42:20:07, 36.29s/it]                                                       {'loss': 0.3946, 'learning_rate': 5e-05, 'epoch': 0.48}
 10%|▉         | 450/4650 [4:32:14<42:20:07, 36.29s/it] 10%|▉         | 451/4650 [4:32:51<42:17:40, 36.26s/it]                                                       {'loss': 0.4164, 'learning_rate': 5e-05, 'epoch': 0.48}
 10%|▉         | 451/4650 [4:32:51<42:17:40, 36.26s/it] 10%|▉         | 452/4650 [4:33:27<42:18:10, 36.28s/it]                                                       {'loss': 0.2907, 'learning_rate': 5e-05, 'epoch': 0.49}
 10%|▉         | 452/4650 [4:33:27<42:18:10, 36.28s/it] 10%|▉         | 453/4650 [4:34:03<42:17:39, 36.28s/it]                                                       {'loss': 0.5215, 'learning_rate': 5e-05, 'epoch': 0.49}
 10%|▉         | 453/4650 [4:34:03<42:17:39, 36.28s/it] 10%|▉         | 454/4650 [4:34:39<42:16:56, 36.28s/it]                                                       {'loss': 0.3741, 'learning_rate': 5e-05, 'epoch': 0.49}
 10%|▉         | 454/4650 [4:34:39<42:16:56, 36.28s/it] 10%|▉         | 455/4650 [4:35:16<42:14:49, 36.25s/it]                                                       {'loss': 0.4877, 'learning_rate': 5e-05, 'epoch': 0.49}
 10%|▉         | 455/4650 [4:35:16<42:14:49, 36.25s/it] 10%|▉         | 456/4650 [4:35:52<42:14:29, 36.26s/it]                                                       {'loss': 0.4338, 'learning_rate': 5e-05, 'epoch': 0.49}
 10%|▉         | 456/4650 [4:35:52<42:14:29, 36.26s/it] 10%|▉         | 457/4650 [4:36:28<42:13:53, 36.26s/it]                                                       {'loss': 0.2988, 'learning_rate': 5e-05, 'epoch': 0.49}
 10%|▉         | 457/4650 [4:36:28<42:13:53, 36.26s/it] 10%|▉         | 458/4650 [4:37:04<42:12:31, 36.25s/it]                                                       {'loss': 0.4938, 'learning_rate': 5e-05, 'epoch': 0.49}
 10%|▉         | 458/4650 [4:37:04<42:12:31, 36.25s/it] 10%|▉         | 459/4650 [4:37:41<42:11:27, 36.24s/it]                                                       {'loss': 0.5851, 'learning_rate': 5e-05, 'epoch': 0.49}
 10%|▉         | 459/4650 [4:37:41<42:11:27, 36.24s/it] 10%|▉         | 460/4650 [4:38:17<42:11:46, 36.25s/it]                                                       {'loss': 0.6206, 'learning_rate': 5e-05, 'epoch': 0.49}
 10%|▉         | 460/4650 [4:38:17<42:11:46, 36.25s/it] 10%|▉         | 461/4650 [4:38:53<42:09:10, 36.23s/it]                                                       {'loss': 0.3444, 'learning_rate': 5e-05, 'epoch': 0.5}
 10%|▉         | 461/4650 [4:38:53<42:09:10, 36.23s/it] 10%|▉         | 462/4650 [4:39:29<42:10:02, 36.25s/it]                                                       {'loss': 0.3869, 'learning_rate': 5e-05, 'epoch': 0.5}
 10%|▉         | 462/4650 [4:39:29<42:10:02, 36.25s/it] 10%|▉         | 463/4650 [4:40:06<42:08:41, 36.24s/it]                                                       {'loss': 0.3232, 'learning_rate': 5e-05, 'epoch': 0.5}
 10%|▉         | 463/4650 [4:40:06<42:08:41, 36.24s/it] 10%|▉         | 464/4650 [4:40:42<42:08:20, 36.24s/it]                                                       {'loss': 0.4951, 'learning_rate': 5e-05, 'epoch': 0.5}
 10%|▉         | 464/4650 [4:40:42<42:08:20, 36.24s/it] 10%|█         | 465/4650 [4:41:18<42:07:40, 36.24s/it]                                                       {'loss': 0.309, 'learning_rate': 5e-05, 'epoch': 0.5}
 10%|█         | 465/4650 [4:41:18<42:07:40, 36.24s/it] 10%|█         | 466/4650 [4:41:54<42:07:15, 36.24s/it]                                                       {'loss': 0.4344, 'learning_rate': 5e-05, 'epoch': 0.5}
 10%|█         | 466/4650 [4:41:54<42:07:15, 36.24s/it] 10%|█         | 467/4650 [4:42:30<42:04:44, 36.21s/it]                                                       {'loss': 0.321, 'learning_rate': 5e-05, 'epoch': 0.5}
 10%|█         | 467/4650 [4:42:30<42:04:44, 36.21s/it] 10%|█         | 468/4650 [4:43:07<42:03:11, 36.20s/it]                                                       {'loss': 0.4622, 'learning_rate': 5e-05, 'epoch': 0.5}
 10%|█         | 468/4650 [4:43:07<42:03:11, 36.20s/it] 10%|█         | 469/4650 [4:43:43<42:03:54, 36.22s/it]                                                       {'loss': 0.281, 'learning_rate': 5e-05, 'epoch': 0.5}
 10%|█         | 469/4650 [4:43:43<42:03:54, 36.22s/it] 10%|█         | 470/4650 [4:44:19<42:02:03, 36.20s/it]                                                       {'loss': 0.3709, 'learning_rate': 5e-05, 'epoch': 0.51}
 10%|█         | 470/4650 [4:44:19<42:02:03, 36.20s/it] 10%|█         | 471/4650 [4:44:55<42:01:20, 36.20s/it]                                                       {'loss': 0.3564, 'learning_rate': 5e-05, 'epoch': 0.51}
 10%|█         | 471/4650 [4:44:55<42:01:20, 36.20s/it] 10%|█         | 472/4650 [4:45:31<41:59:49, 36.19s/it]                                                       {'loss': 0.3627, 'learning_rate': 5e-05, 'epoch': 0.51}
 10%|█         | 472/4650 [4:45:31<41:59:49, 36.19s/it] 10%|█         | 473/4650 [4:46:08<41:58:50, 36.18s/it]                                                       {'loss': 0.4889, 'learning_rate': 5e-05, 'epoch': 0.51}
 10%|█         | 473/4650 [4:46:08<41:58:50, 36.18s/it] 10%|█         | 474/4650 [4:46:44<41:58:10, 36.18s/it]                                                       {'loss': 0.5051, 'learning_rate': 5e-05, 'epoch': 0.51}
 10%|█         | 474/4650 [4:46:44<41:58:10, 36.18s/it] 10%|█         | 475/4650 [4:47:20<41:57:19, 36.18s/it]                                                       {'loss': 0.4631, 'learning_rate': 5e-05, 'epoch': 0.51}
 10%|█         | 475/4650 [4:47:20<41:57:19, 36.18s/it] 10%|█         | 476/4650 [4:47:56<41:56:14, 36.17s/it]                                                       {'loss': 0.7239, 'learning_rate': 5e-05, 'epoch': 0.51}
 10%|█         | 476/4650 [4:47:56<41:56:14, 36.17s/it] 10%|█         | 477/4650 [4:48:32<41:54:58, 36.16s/it]                                                       {'loss': 0.4223, 'learning_rate': 5e-05, 'epoch': 0.51}
 10%|█         | 477/4650 [4:48:32<41:54:58, 36.16s/it] 10%|█         | 478/4650 [4:49:08<41:54:30, 36.16s/it]                                                       {'loss': 0.3545, 'learning_rate': 5e-05, 'epoch': 0.51}
 10%|█         | 478/4650 [4:49:08<41:54:30, 36.16s/it] 10%|█         | 479/4650 [4:49:44<41:53:22, 36.15s/it]                                                       {'loss': 0.3005, 'learning_rate': 5e-05, 'epoch': 0.51}
 10%|█         | 479/4650 [4:49:45<41:53:22, 36.15s/it] 10%|█         | 480/4650 [4:50:21<41:53:16, 36.16s/it]                                                       {'loss': 0.5347, 'learning_rate': 5e-05, 'epoch': 0.52}
 10%|█         | 480/4650 [4:50:21<41:53:16, 36.16s/it] 10%|█         | 481/4650 [4:50:57<41:52:04, 36.15s/it]                                                       {'loss': 0.36, 'learning_rate': 5e-05, 'epoch': 0.52}
 10%|█         | 481/4650 [4:50:57<41:52:04, 36.15s/it] 10%|█         | 482/4650 [4:51:33<41:52:02, 36.16s/it]                                                       {'loss': 0.4104, 'learning_rate': 5e-05, 'epoch': 0.52}
 10%|█         | 482/4650 [4:51:33<41:52:02, 36.16s/it] 10%|█         | 483/4650 [4:52:09<41:49:37, 36.14s/it]                                                       {'loss': 0.2927, 'learning_rate': 5e-05, 'epoch': 0.52}
 10%|█         | 483/4650 [4:52:09<41:49:37, 36.14s/it] 10%|█         | 484/4650 [4:52:45<41:49:05, 36.14s/it]                                                       {'loss': 0.5656, 'learning_rate': 5e-05, 'epoch': 0.52}
 10%|█         | 484/4650 [4:52:45<41:49:05, 36.14s/it] 10%|█         | 485/4650 [4:53:21<41:47:28, 36.12s/it]                                                       {'loss': 0.3442, 'learning_rate': 5e-05, 'epoch': 0.52}
 10%|█         | 485/4650 [4:53:21<41:47:28, 36.12s/it] 10%|█         | 486/4650 [4:53:58<41:49:49, 36.16s/it]                                                       {'loss': 0.335, 'learning_rate': 5e-05, 'epoch': 0.52}
 10%|█         | 486/4650 [4:53:58<41:49:49, 36.16s/it] 10%|█         | 487/4650 [4:54:34<41:50:07, 36.18s/it]                                                       {'loss': 0.3444, 'learning_rate': 5e-05, 'epoch': 0.52}
 10%|█         | 487/4650 [4:54:34<41:50:07, 36.18s/it] 10%|█         | 488/4650 [4:55:10<41:50:45, 36.20s/it]                                                       {'loss': 0.55, 'learning_rate': 5e-05, 'epoch': 0.52}
 10%|█         | 488/4650 [4:55:10<41:50:45, 36.20s/it] 11%|█         | 489/4650 [4:55:46<41:49:00, 36.18s/it]                                                       {'loss': 0.4866, 'learning_rate': 5e-05, 'epoch': 0.53}
 11%|█         | 489/4650 [4:55:46<41:49:00, 36.18s/it] 11%|█         | 490/4650 [4:56:22<41:49:06, 36.19s/it]                                                       {'loss': 0.4, 'learning_rate': 5e-05, 'epoch': 0.53}
 11%|█         | 490/4650 [4:56:22<41:49:06, 36.19s/it] 11%|█         | 491/4650 [4:56:59<41:47:59, 36.18s/it]                                                       {'loss': 0.543, 'learning_rate': 5e-05, 'epoch': 0.53}
 11%|█         | 491/4650 [4:56:59<41:47:59, 36.18s/it] 11%|█         | 492/4650 [4:57:35<41:47:35, 36.18s/it]                                                       {'loss': 0.5394, 'learning_rate': 5e-05, 'epoch': 0.53}
 11%|█         | 492/4650 [4:57:35<41:47:35, 36.18s/it] 11%|█         | 493/4650 [4:58:11<41:46:49, 36.18s/it]                                                       {'loss': 0.5304, 'learning_rate': 5e-05, 'epoch': 0.53}
 11%|█         | 493/4650 [4:58:11<41:46:49, 36.18s/it] 11%|█         | 494/4650 [4:58:47<41:46:15, 36.18s/it]                                                       {'loss': 0.4645, 'learning_rate': 5e-05, 'epoch': 0.53}
 11%|█         | 494/4650 [4:58:47<41:46:15, 36.18s/it] 11%|█         | 495/4650 [4:59:23<41:46:16, 36.19s/it]                                                       {'loss': 0.613, 'learning_rate': 5e-05, 'epoch': 0.53}
 11%|█         | 495/4650 [4:59:23<41:46:16, 36.19s/it] 11%|█         | 496/4650 [4:59:59<41:45:13, 36.19s/it]                                                       {'loss': 0.4011, 'learning_rate': 5e-05, 'epoch': 0.53}
 11%|█         | 496/4650 [4:59:59<41:45:13, 36.19s/it] 11%|█         | 497/4650 [5:00:36<41:43:03, 36.16s/it]                                                       {'loss': 0.2787, 'learning_rate': 5e-05, 'epoch': 0.53}
 11%|█         | 497/4650 [5:00:36<41:43:03, 36.16s/it] 11%|█         | 498/4650 [5:01:12<41:42:32, 36.16s/it]                                                       {'loss': 0.5139, 'learning_rate': 5e-05, 'epoch': 0.54}
 11%|█         | 498/4650 [5:01:12<41:42:32, 36.16s/it] 11%|█         | 499/4650 [5:01:48<41:40:42, 36.15s/it]                                                       {'loss': 0.4319, 'learning_rate': 5e-05, 'epoch': 0.54}
 11%|█         | 499/4650 [5:01:48<41:40:42, 36.15s/it] 11%|█         | 500/4650 [5:02:24<41:40:11, 36.15s/it]                                                       {'loss': 0.534, 'learning_rate': 5e-05, 'epoch': 0.54}
 11%|█         | 500/4650 [5:02:24<41:40:11, 36.15s/it] 11%|█         | 501/4650 [5:03:00<41:39:00, 36.14s/it]                                                       {'loss': 0.3983, 'learning_rate': 5e-05, 'epoch': 0.54}
 11%|█         | 501/4650 [5:03:00<41:39:00, 36.14s/it] 11%|█         | 502/4650 [5:03:36<41:38:01, 36.13s/it]                                                       {'loss': 0.5247, 'learning_rate': 5e-05, 'epoch': 0.54}
 11%|█         | 502/4650 [5:03:36<41:38:01, 36.13s/it] 11%|█         | 503/4650 [5:04:12<41:39:46, 36.17s/it]                                                       {'loss': 0.407, 'learning_rate': 5e-05, 'epoch': 0.54}
 11%|█         | 503/4650 [5:04:12<41:39:46, 36.17s/it] 11%|█         | 504/4650 [5:04:49<41:38:48, 36.16s/it]                                                       {'loss': 0.5399, 'learning_rate': 5e-05, 'epoch': 0.54}
 11%|█         | 504/4650 [5:04:49<41:38:48, 36.16s/it] 11%|█         | 505/4650 [5:05:25<41:37:54, 36.16s/it]                                                       {'loss': 0.3244, 'learning_rate': 5e-05, 'epoch': 0.54}
 11%|█         | 505/4650 [5:05:25<41:37:54, 36.16s/it] 11%|█         | 506/4650 [5:06:01<41:37:43, 36.16s/it]                                                       {'loss': 0.5505, 'learning_rate': 5e-05, 'epoch': 0.54}
 11%|█         | 506/4650 [5:06:01<41:37:43, 36.16s/it] 11%|█         | 507/4650 [5:06:37<41:36:15, 36.15s/it]                                                       {'loss': 0.5828, 'learning_rate': 5e-05, 'epoch': 0.54}
 11%|█         | 507/4650 [5:06:37<41:36:15, 36.15s/it] 11%|█         | 508/4650 [5:07:13<41:36:01, 36.16s/it]                                                       {'loss': 0.5428, 'learning_rate': 5e-05, 'epoch': 0.55}
 11%|█         | 508/4650 [5:07:13<41:36:01, 36.16s/it] 11%|█         | 509/4650 [5:07:49<41:36:35, 36.17s/it]                                                       {'loss': 0.4692, 'learning_rate': 5e-05, 'epoch': 0.55}
 11%|█         | 509/4650 [5:07:49<41:36:35, 36.17s/it] 11%|█         | 510/4650 [5:08:26<41:36:17, 36.18s/it]                                                       {'loss': 0.3196, 'learning_rate': 5e-05, 'epoch': 0.55}
 11%|█         | 510/4650 [5:08:26<41:36:17, 36.18s/it] 11%|█         | 511/4650 [5:09:02<41:35:31, 36.18s/it]                                                       {'loss': 0.6359, 'learning_rate': 5e-05, 'epoch': 0.55}
 11%|█         | 511/4650 [5:09:02<41:35:31, 36.18s/it] 11%|█         | 512/4650 [5:09:38<41:33:53, 36.16s/it]                                                       {'loss': 0.4168, 'learning_rate': 5e-05, 'epoch': 0.55}
 11%|█         | 512/4650 [5:09:38<41:33:53, 36.16s/it] 11%|█         | 513/4650 [5:10:14<41:32:23, 36.15s/it]                                                       {'loss': 0.4528, 'learning_rate': 5e-05, 'epoch': 0.55}
 11%|█         | 513/4650 [5:10:14<41:32:23, 36.15s/it] 11%|█         | 514/4650 [5:10:50<41:31:30, 36.14s/it]                                                       {'loss': 0.3254, 'learning_rate': 5e-05, 'epoch': 0.55}
 11%|█         | 514/4650 [5:10:50<41:31:30, 36.14s/it] 11%|█         | 515/4650 [5:11:26<41:30:23, 36.14s/it]                                                       {'loss': 0.3952, 'learning_rate': 5e-05, 'epoch': 0.55}
 11%|█         | 515/4650 [5:11:26<41:30:23, 36.14s/it] 11%|█         | 516/4650 [5:12:02<41:30:07, 36.14s/it]                                                       {'loss': 0.2721, 'learning_rate': 5e-05, 'epoch': 0.55}
 11%|█         | 516/4650 [5:12:02<41:30:07, 36.14s/it] 11%|█         | 517/4650 [5:12:39<41:28:08, 36.12s/it]                                                       {'loss': 0.2502, 'learning_rate': 5e-05, 'epoch': 0.56}
 11%|█         | 517/4650 [5:12:39<41:28:08, 36.12s/it] 11%|█         | 518/4650 [5:13:15<41:26:46, 36.11s/it]                                                       {'loss': 0.2879, 'learning_rate': 5e-05, 'epoch': 0.56}
 11%|█         | 518/4650 [5:13:15<41:26:46, 36.11s/it] 11%|█         | 519/4650 [5:13:51<41:27:29, 36.13s/it]                                                       {'loss': 0.507, 'learning_rate': 5e-05, 'epoch': 0.56}
 11%|█         | 519/4650 [5:13:51<41:27:29, 36.13s/it] 11%|█         | 520/4650 [5:14:27<41:34:19, 36.24s/it]                                                       {'loss': 0.2131, 'learning_rate': 5e-05, 'epoch': 0.56}
 11%|█         | 520/4650 [5:14:27<41:34:19, 36.24s/it] 11%|█         | 521/4650 [5:15:03<41:31:26, 36.20s/it]                                                       {'loss': 0.4671, 'learning_rate': 5e-05, 'epoch': 0.56}
 11%|█         | 521/4650 [5:15:03<41:31:26, 36.20s/it] 11%|█         | 522/4650 [5:15:40<41:30:47, 36.20s/it]                                                       {'loss': 0.3626, 'learning_rate': 5e-05, 'epoch': 0.56}
 11%|█         | 522/4650 [5:15:40<41:30:47, 36.20s/it] 11%|█         | 523/4650 [5:16:16<41:29:21, 36.19s/it]                                                       {'loss': 0.4705, 'learning_rate': 5e-05, 'epoch': 0.56}
 11%|█         | 523/4650 [5:16:16<41:29:21, 36.19s/it] 11%|█▏        | 524/4650 [5:16:52<41:30:37, 36.22s/it]                                                       {'loss': 0.2539, 'learning_rate': 5e-05, 'epoch': 0.56}
 11%|█▏        | 524/4650 [5:16:52<41:30:37, 36.22s/it] 11%|█▏        | 525/4650 [5:17:28<41:28:07, 36.19s/it]                                                       {'loss': 0.3298, 'learning_rate': 5e-05, 'epoch': 0.56}
 11%|█▏        | 525/4650 [5:17:28<41:28:07, 36.19s/it] 11%|█▏        | 526/4650 [5:18:04<41:27:08, 36.19s/it]                                                       {'loss': 0.4442, 'learning_rate': 5e-05, 'epoch': 0.57}
 11%|█▏        | 526/4650 [5:18:04<41:27:08, 36.19s/it] 11%|█▏        | 527/4650 [5:18:41<41:26:06, 36.18s/it]                                                       {'loss': 0.2461, 'learning_rate': 5e-05, 'epoch': 0.57}
 11%|█▏        | 527/4650 [5:18:41<41:26:06, 36.18s/it] 11%|█▏        | 528/4650 [5:19:17<41:25:22, 36.18s/it]                                                       {'loss': 0.4361, 'learning_rate': 5e-05, 'epoch': 0.57}
 11%|█▏        | 528/4650 [5:19:17<41:25:22, 36.18s/it] 11%|█▏        | 529/4650 [5:19:53<41:25:21, 36.19s/it]                                                       {'loss': 0.6088, 'learning_rate': 5e-05, 'epoch': 0.57}
 11%|█▏        | 529/4650 [5:19:53<41:25:21, 36.19s/it] 11%|█▏        | 530/4650 [5:20:29<41:25:51, 36.20s/it]                                                       {'loss': 0.381, 'learning_rate': 5e-05, 'epoch': 0.57}
 11%|█▏        | 530/4650 [5:20:29<41:25:51, 36.20s/it] 11%|█▏        | 531/4650 [5:21:05<41:26:36, 36.22s/it]                                                       {'loss': 0.4217, 'learning_rate': 5e-05, 'epoch': 0.57}
 11%|█▏        | 531/4650 [5:21:05<41:26:36, 36.22s/it] 11%|█▏        | 532/4650 [5:21:42<41:27:55, 36.25s/it]                                                       {'loss': 0.4727, 'learning_rate': 5e-05, 'epoch': 0.57}
 11%|█▏        | 532/4650 [5:21:42<41:27:55, 36.25s/it] 11%|█▏        | 533/4650 [5:22:18<41:26:35, 36.24s/it]                                                       {'loss': 0.3025, 'learning_rate': 5e-05, 'epoch': 0.57}
 11%|█▏        | 533/4650 [5:22:18<41:26:35, 36.24s/it] 11%|█▏        | 534/4650 [5:22:54<41:26:44, 36.25s/it]                                                       {'loss': 0.3238, 'learning_rate': 5e-05, 'epoch': 0.57}
 11%|█▏        | 534/4650 [5:22:54<41:26:44, 36.25s/it] 12%|█▏        | 535/4650 [5:23:31<41:27:06, 36.26s/it]                                                       {'loss': 0.3404, 'learning_rate': 5e-05, 'epoch': 0.57}
 12%|█▏        | 535/4650 [5:23:31<41:27:06, 36.26s/it] 12%|█▏        | 536/4650 [5:24:07<41:27:59, 36.29s/it]                                                       {'loss': 0.3319, 'learning_rate': 5e-05, 'epoch': 0.58}
 12%|█▏        | 536/4650 [5:24:07<41:27:59, 36.29s/it] 12%|█▏        | 537/4650 [5:24:43<41:28:39, 36.30s/it]                                                       {'loss': 0.1379, 'learning_rate': 5e-05, 'epoch': 0.58}
 12%|█▏        | 537/4650 [5:24:43<41:28:39, 36.30s/it] 12%|█▏        | 538/4650 [5:25:20<41:28:38, 36.31s/it]                                                       {'loss': 0.5597, 'learning_rate': 5e-05, 'epoch': 0.58}
 12%|█▏        | 538/4650 [5:25:20<41:28:38, 36.31s/it] 12%|█▏        | 539/4650 [5:25:56<41:27:37, 36.31s/it]                                                       {'loss': 0.4254, 'learning_rate': 5e-05, 'epoch': 0.58}
 12%|█▏        | 539/4650 [5:25:56<41:27:37, 36.31s/it] 12%|█▏        | 540/4650 [5:26:32<41:26:52, 36.30s/it]                                                       {'loss': 0.5735, 'learning_rate': 5e-05, 'epoch': 0.58}
 12%|█▏        | 540/4650 [5:26:32<41:26:52, 36.30s/it] 12%|█▏        | 541/4650 [5:27:08<41:27:26, 36.32s/it]                                                       {'loss': 0.5005, 'learning_rate': 5e-05, 'epoch': 0.58}
 12%|█▏        | 541/4650 [5:27:08<41:27:26, 36.32s/it] 12%|█▏        | 542/4650 [5:27:45<41:27:22, 36.33s/it]                                                       {'loss': 0.375, 'learning_rate': 5e-05, 'epoch': 0.58}
 12%|█▏        | 542/4650 [5:27:45<41:27:22, 36.33s/it] 12%|█▏        | 543/4650 [5:28:21<41:27:03, 36.33s/it]                                                       {'loss': 0.4723, 'learning_rate': 5e-05, 'epoch': 0.58}
 12%|█▏        | 543/4650 [5:28:21<41:27:03, 36.33s/it] 12%|█▏        | 544/4650 [5:28:58<41:27:32, 36.35s/it]                                                       {'loss': 0.5629, 'learning_rate': 5e-05, 'epoch': 0.58}
 12%|█▏        | 544/4650 [5:28:58<41:27:32, 36.35s/it] 12%|█▏        | 545/4650 [5:29:34<41:25:43, 36.33s/it]                                                       {'loss': 0.4395, 'learning_rate': 5e-05, 'epoch': 0.59}
 12%|█▏        | 545/4650 [5:29:34<41:25:43, 36.33s/it] 12%|█▏        | 546/4650 [5:30:10<41:26:20, 36.35s/it]                                                       {'loss': 0.3543, 'learning_rate': 5e-05, 'epoch': 0.59}
 12%|█▏        | 546/4650 [5:30:10<41:26:20, 36.35s/it] 12%|█▏        | 547/4650 [5:30:47<41:27:24, 36.37s/it]                                                       {'loss': 0.4356, 'learning_rate': 5e-05, 'epoch': 0.59}
 12%|█▏        | 547/4650 [5:30:47<41:27:24, 36.37s/it] 12%|█▏        | 548/4650 [5:31:23<41:26:18, 36.37s/it]                                                       {'loss': 0.429, 'learning_rate': 5e-05, 'epoch': 0.59}
 12%|█▏        | 548/4650 [5:31:23<41:26:18, 36.37s/it] 12%|█▏        | 549/4650 [5:31:59<41:25:01, 36.36s/it]                                                       {'loss': 0.3374, 'learning_rate': 5e-05, 'epoch': 0.59}
 12%|█▏        | 549/4650 [5:31:59<41:25:01, 36.36s/it] 12%|█▏        | 550/4650 [5:32:36<41:24:41, 36.36s/it]                                                       {'loss': 0.3462, 'learning_rate': 5e-05, 'epoch': 0.59}
 12%|█▏        | 550/4650 [5:32:36<41:24:41, 36.36s/it] 12%|█▏        | 551/4650 [5:33:12<41:24:06, 36.36s/it]                                                       {'loss': 0.3281, 'learning_rate': 5e-05, 'epoch': 0.59}
 12%|█▏        | 551/4650 [5:33:12<41:24:06, 36.36s/it] 12%|█▏        | 552/4650 [5:33:49<41:24:56, 36.38s/it]                                                       {'loss': 0.228, 'learning_rate': 5e-05, 'epoch': 0.59}
 12%|█▏        | 552/4650 [5:33:49<41:24:56, 36.38s/it] 12%|█▏        | 553/4650 [5:34:25<41:26:34, 36.42s/it]                                                       {'loss': 0.2403, 'learning_rate': 5e-05, 'epoch': 0.59}
 12%|█▏        | 553/4650 [5:34:25<41:26:34, 36.42s/it] 12%|█▏        | 554/4650 [5:35:01<41:27:01, 36.43s/it]                                                       {'loss': 0.3244, 'learning_rate': 5e-05, 'epoch': 0.6}
 12%|█▏        | 554/4650 [5:35:01<41:27:01, 36.43s/it] 12%|█▏        | 555/4650 [5:35:38<41:24:46, 36.41s/it]                                                       {'loss': 0.54, 'learning_rate': 5e-05, 'epoch': 0.6}
 12%|█▏        | 555/4650 [5:35:38<41:24:46, 36.41s/it] 12%|█▏        | 556/4650 [5:36:14<41:23:28, 36.40s/it]                                                       {'loss': 0.4595, 'learning_rate': 5e-05, 'epoch': 0.6}
 12%|█▏        | 556/4650 [5:36:14<41:23:28, 36.40s/it] 12%|█▏        | 557/4650 [5:36:51<41:22:46, 36.40s/it]                                                       {'loss': 0.4427, 'learning_rate': 5e-05, 'epoch': 0.6}
 12%|█▏        | 557/4650 [5:36:51<41:22:46, 36.40s/it] 12%|█▏        | 558/4650 [5:37:27<41:22:53, 36.41s/it]                                                       {'loss': 0.2102, 'learning_rate': 5e-05, 'epoch': 0.6}
 12%|█▏        | 558/4650 [5:37:27<41:22:53, 36.41s/it] 12%|█▏        | 559/4650 [5:38:03<41:20:35, 36.38s/it]                                                       {'loss': 0.5089, 'learning_rate': 5e-05, 'epoch': 0.6}
 12%|█▏        | 559/4650 [5:38:03<41:20:35, 36.38s/it] 12%|█▏        | 560/4650 [5:38:40<41:19:17, 36.37s/it]                                                       {'loss': 0.259, 'learning_rate': 5e-05, 'epoch': 0.6}
 12%|█▏        | 560/4650 [5:38:40<41:19:17, 36.37s/it] 12%|█▏        | 561/4650 [5:39:16<41:21:17, 36.41s/it]                                                       {'loss': 0.3345, 'learning_rate': 5e-05, 'epoch': 0.6}
 12%|█▏        | 561/4650 [5:39:16<41:21:17, 36.41s/it] 12%|█▏        | 562/4650 [5:39:53<41:21:04, 36.41s/it]                                                       {'loss': 0.3656, 'learning_rate': 5e-05, 'epoch': 0.6}
 12%|█▏        | 562/4650 [5:39:53<41:21:04, 36.41s/it] 12%|█▏        | 563/4650 [5:40:29<41:20:32, 36.42s/it]                                                       {'loss': 0.3833, 'learning_rate': 5e-05, 'epoch': 0.61}
 12%|█▏        | 563/4650 [5:40:29<41:20:32, 36.42s/it] 12%|█▏        | 564/4650 [5:41:06<41:22:01, 36.45s/it]                                                       {'loss': 0.3283, 'learning_rate': 5e-05, 'epoch': 0.61}
 12%|█▏        | 564/4650 [5:41:06<41:22:01, 36.45s/it] 12%|█▏        | 565/4650 [5:41:42<41:19:54, 36.42s/it]                                                       {'loss': 0.2581, 'learning_rate': 5e-05, 'epoch': 0.61}
 12%|█▏        | 565/4650 [5:41:42<41:19:54, 36.42s/it] 12%|█▏        | 566/4650 [5:42:18<41:19:23, 36.43s/it]                                                       {'loss': 0.4774, 'learning_rate': 5e-05, 'epoch': 0.61}
 12%|█▏        | 566/4650 [5:42:18<41:19:23, 36.43s/it] 12%|█▏        | 567/4650 [5:42:55<41:18:00, 36.41s/it]                                                       {'loss': 0.3545, 'learning_rate': 5e-05, 'epoch': 0.61}
 12%|█▏        | 567/4650 [5:42:55<41:18:00, 36.41s/it] 12%|█▏        | 568/4650 [5:43:31<41:17:51, 36.42s/it]                                                       {'loss': 0.4816, 'learning_rate': 5e-05, 'epoch': 0.61}
 12%|█▏        | 568/4650 [5:43:31<41:17:51, 36.42s/it] 12%|█▏        | 569/4650 [5:44:08<41:16:48, 36.41s/it]                                                       {'loss': 0.21, 'learning_rate': 5e-05, 'epoch': 0.61}
 12%|█▏        | 569/4650 [5:44:08<41:16:48, 36.41s/it] 12%|█▏        | 570/4650 [5:44:44<41:19:51, 36.47s/it]                                                       {'loss': 0.4542, 'learning_rate': 5e-05, 'epoch': 0.61}
 12%|█▏        | 570/4650 [5:44:44<41:19:51, 36.47s/it] 12%|█▏        | 571/4650 [5:45:21<41:20:52, 36.49s/it]                                                       {'loss': 0.2063, 'learning_rate': 5e-05, 'epoch': 0.61}
 12%|█▏        | 571/4650 [5:45:21<41:20:52, 36.49s/it] 12%|█▏        | 572/4650 [5:45:57<41:17:40, 36.45s/it]                                                       {'loss': 0.5241, 'learning_rate': 5e-05, 'epoch': 0.61}
 12%|█▏        | 572/4650 [5:45:57<41:17:40, 36.45s/it] 12%|█▏        | 573/4650 [5:46:33<41:15:44, 36.43s/it]                                                       {'loss': 0.4601, 'learning_rate': 5e-05, 'epoch': 0.62}
 12%|█▏        | 573/4650 [5:46:33<41:15:44, 36.43s/it] 12%|█▏        | 574/4650 [5:47:10<41:17:43, 36.47s/it]                                                       {'loss': 0.3466, 'learning_rate': 5e-05, 'epoch': 0.62}
 12%|█▏        | 574/4650 [5:47:10<41:17:43, 36.47s/it] 12%|█▏        | 575/4650 [5:47:47<41:20:07, 36.52s/it]                                                       {'loss': 0.3488, 'learning_rate': 5e-05, 'epoch': 0.62}
 12%|█▏        | 575/4650 [5:47:47<41:20:07, 36.52s/it] 12%|█▏        | 576/4650 [5:48:23<41:17:15, 36.48s/it]                                                       {'loss': 0.3972, 'learning_rate': 5e-05, 'epoch': 0.62}
 12%|█▏        | 576/4650 [5:48:23<41:17:15, 36.48s/it] 12%|█▏        | 577/4650 [5:48:59<41:15:22, 36.47s/it]                                                       {'loss': 0.2849, 'learning_rate': 5e-05, 'epoch': 0.62}
 12%|█▏        | 577/4650 [5:48:59<41:15:22, 36.47s/it] 12%|█▏        | 578/4650 [5:49:36<41:16:14, 36.49s/it]                                                       {'loss': 0.4362, 'learning_rate': 5e-05, 'epoch': 0.62}
 12%|█▏        | 578/4650 [5:49:36<41:16:14, 36.49s/it] 12%|█▏        | 579/4650 [5:50:13<41:18:01, 36.52s/it]                                                       {'loss': 0.2621, 'learning_rate': 5e-05, 'epoch': 0.62}
 12%|█▏        | 579/4650 [5:50:13<41:18:01, 36.52s/it] 12%|█▏        | 580/4650 [5:50:49<41:15:27, 36.49s/it]                                                       {'loss': 0.426, 'learning_rate': 5e-05, 'epoch': 0.62}
 12%|█▏        | 580/4650 [5:50:49<41:15:27, 36.49s/it] 12%|█▏        | 581/4650 [5:51:26<41:14:55, 36.49s/it]                                                       {'loss': 0.2976, 'learning_rate': 5e-05, 'epoch': 0.62}
 12%|█▏        | 581/4650 [5:51:26<41:14:55, 36.49s/it] 13%|█▎        | 582/4650 [5:52:02<41:13:13, 36.48s/it]                                                       {'loss': 0.2666, 'learning_rate': 5e-05, 'epoch': 0.63}
 13%|█▎        | 582/4650 [5:52:02<41:13:13, 36.48s/it] 13%|█▎        | 583/4650 [5:52:38<41:11:53, 36.47s/it]                                                       {'loss': 0.223, 'learning_rate': 5e-05, 'epoch': 0.63}
 13%|█▎        | 583/4650 [5:52:38<41:11:53, 36.47s/it]